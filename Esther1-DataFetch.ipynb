{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b203911",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ca0c284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.2.4)\n",
      "Requirement already satisfied: numpy in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (1.22.4)\n",
      "Requirement already satisfied: seaborn in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (0.11.1)\n",
      "Requirement already satisfied: matplotlib in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (3.3.4)\n",
      "Requirement already satisfied: sqlalchemy==1.4.39 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (1.4.39)\n",
      "Requirement already satisfied: loguru==0.6.0 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (0.6.0)\n",
      "Requirement already satisfied: networkx==2.6.3 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (2.6.3)\n",
      "Requirement already satisfied: transformers in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 8)) (4.26.1)\n",
      "Requirement already satisfied: wordcloud==1.8.2.2 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 9)) (1.8.2.2)\n",
      "Requirement already satisfied: umap-learn in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 10)) (0.5.3)\n",
      "Requirement already satisfied: pyLDAvis==2.1.2 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 11)) (2.1.2)\n",
      "Requirement already satisfied: holoviews in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 12)) (1.15.4)\n",
      "Requirement already satisfied: bokeh in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 13)) (2.4.3)\n",
      "Requirement already satisfied: sklearn in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 14)) (0.0.post1)\n",
      "Requirement already satisfied: openai in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 15)) (0.27.0)\n",
      "Requirement already satisfied: wandb in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 16)) (0.13.10)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from sqlalchemy==1.4.39->-r requirements.txt (line 5)) (1.0.0)\n",
      "Requirement already satisfied: pillow in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from wordcloud==1.8.2.2->-r requirements.txt (line 9)) (8.2.0)\n",
      "Requirement already satisfied: wheel>=0.23.0 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from pyLDAvis==2.1.2->-r requirements.txt (line 11)) (0.36.2)\n",
      "Requirement already satisfied: future in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from pyLDAvis==2.1.2->-r requirements.txt (line 11)) (0.18.2)\n",
      "Requirement already satisfied: jinja2>=2.7.2 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from pyLDAvis==2.1.2->-r requirements.txt (line 11)) (3.0.2)\n",
      "Requirement already satisfied: scipy>=0.18.0 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from pyLDAvis==2.1.2->-r requirements.txt (line 11)) (1.6.2)\n",
      "Requirement already satisfied: joblib>=0.8.4 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from pyLDAvis==2.1.2->-r requirements.txt (line 11)) (1.0.1)\n",
      "Requirement already satisfied: funcy in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from pyLDAvis==2.1.2->-r requirements.txt (line 11)) (1.18)\n",
      "Requirement already satisfied: numexpr in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from pyLDAvis==2.1.2->-r requirements.txt (line 11)) (2.7.3)\n",
      "Requirement already satisfied: pytest in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from pyLDAvis==2.1.2->-r requirements.txt (line 11)) (6.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from pandas->-r requirements.txt (line 1)) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from pandas->-r requirements.txt (line 1)) (2021.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 4)) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 4)) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 8)) (21.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 8)) (0.12.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 8)) (2021.4.4)\n",
      "Requirement already satisfied: requests in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 8)) (2.28.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 8)) (0.13.2)\n",
      "Requirement already satisfied: filelock in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 8)) (3.0.12)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 8)) (5.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 8)) (4.59.0)\n",
      "Requirement already satisfied: numba>=0.49 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from umap-learn->-r requirements.txt (line 10)) (0.53.1)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from umap-learn->-r requirements.txt (line 10)) (0.5.8)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from umap-learn->-r requirements.txt (line 10)) (0.24.1)\n",
      "Requirement already satisfied: panel>=0.13.1 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from holoviews->-r requirements.txt (line 12)) (0.14.4)\n",
      "Requirement already satisfied: pyviz-comms>=0.7.4 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from holoviews->-r requirements.txt (line 12)) (2.2.1)\n",
      "Requirement already satisfied: param<2.0,>=1.9.3 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from holoviews->-r requirements.txt (line 12)) (1.12.3)\n",
      "Requirement already satisfied: colorcet in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from holoviews->-r requirements.txt (line 12)) (3.0.1)\n",
      "Requirement already satisfied: tornado>=5.1 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from bokeh->-r requirements.txt (line 13)) (6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from bokeh->-r requirements.txt (line 13)) (4.5.0)\n",
      "Requirement already satisfied: aiohttp in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from openai->-r requirements.txt (line 15)) (3.8.4)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 16)) (0.4.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 16)) (5.8.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 16)) (3.19.6)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 16)) (1.16.0)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 16)) (1.4.4)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 16)) (7.1.2)\n",
      "Requirement already satisfied: setuptools in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 16)) (52.0.0.post20210125)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 16)) (3.1.31)\n",
      "Requirement already satisfied: setproctitle in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 16)) (1.3.2)\n",
      "Requirement already satisfied: pathtools in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 16)) (0.1.2)\n",
      "Requirement already satisfied: six in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from cycler>=0.10->matplotlib->-r requirements.txt (line 4)) (1.15.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from GitPython>=1.0.0->wandb->-r requirements.txt (line 16)) (4.0.10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from jinja2>=2.7.2->pyLDAvis==2.1.2->-r requirements.txt (line 11)) (2.0.1)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from numba>=0.49->umap-learn->-r requirements.txt (line 10)) (0.36.0)\n",
      "Requirement already satisfied: markdown in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from panel>=0.13.1->holoviews->-r requirements.txt (line 12)) (3.4.1)\n",
      "Requirement already satisfied: pyct>=0.4.4 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from panel>=0.13.1->holoviews->-r requirements.txt (line 12)) (0.5.0)\n",
      "Requirement already satisfied: bleach in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from panel>=0.13.1->holoviews->-r requirements.txt (line 12)) (3.3.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers->-r requirements.txt (line 8)) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers->-r requirements.txt (line 8)) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers->-r requirements.txt (line 8)) (2020.12.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers->-r requirements.txt (line 8)) (2.10)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.22->umap-learn->-r requirements.txt (line 10)) (2.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from aiohttp->openai->-r requirements.txt (line 15)) (6.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from aiohttp->openai->-r requirements.txt (line 15)) (20.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from aiohttp->openai->-r requirements.txt (line 15)) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from aiohttp->openai->-r requirements.txt (line 15)) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from aiohttp->openai->-r requirements.txt (line 15)) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from aiohttp->openai->-r requirements.txt (line 15)) (1.8.2)\n",
      "Requirement already satisfied: iniconfig in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from pytest->pyLDAvis==2.1.2->-r requirements.txt (line 11)) (1.1.1)\n",
      "Requirement already satisfied: pluggy<1.0.0a1,>=0.12 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from pytest->pyLDAvis==2.1.2->-r requirements.txt (line 11)) (0.13.1)\n",
      "Requirement already satisfied: py>=1.8.2 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from pytest->pyLDAvis==2.1.2->-r requirements.txt (line 11)) (1.10.0)\n",
      "Requirement already satisfied: toml in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from pytest->pyLDAvis==2.1.2->-r requirements.txt (line 11)) (0.10.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb->-r requirements.txt (line 16)) (5.0.0)\n",
      "Requirement already satisfied: webencodings in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from bleach->panel>=0.13.1->holoviews->-r requirements.txt (line 12)) (0.5.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from markdown->panel>=0.13.1->holoviews->-r requirements.txt (line 12)) (4.12.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown->panel>=0.13.1->holoviews->-r requirements.txt (line 12)) (3.4.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a743d2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from scripts.api import *\n",
    "\n",
    "from scripts.create_graph import *\n",
    "import networkx as nx\n",
    "import networkx.algorithms.community as nx_comm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7142c34e",
   "metadata": {},
   "source": [
    "# Fetch 5 gpt generations data\n",
    "\n",
    "gpt 1.0 - June 11, 2018\n",
    "\n",
    "gpt 2.0 - Feburary 14, 2019\n",
    "\n",
    "gpt 3.0 - June 11, 2020\n",
    "\n",
    "gpt 3.5 - March 15, 2022\n",
    "\n",
    "gpt 4.0 - Match 14, 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a62636b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-22 16:24:07.683] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:24:08.967] [INFO] [api:fetch:236] Fetched 6 tweets\n"
     ]
    }
   ],
   "source": [
    "# gpt-1 before\n",
    "target_total = 30000\n",
    "keyword = 'gpt'\n",
    "start_date = '2018-06-08'   \n",
    "end_date = '2018-06-11'\n",
    "retweets = False\n",
    "before_1 = History.fetch(keyword=keyword, start_date= start_date, end_date= end_date, \n",
    "                    target_total=target_total, retweets=retweets) \n",
    "col_name = before_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "316f37d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-22 16:25:13.670] [INFO] [api:write:61] Writing 103 rows to table before_1\n"
     ]
    }
   ],
   "source": [
    "# write file\n",
    "fname_db = f\"data/esther\"  \n",
    "DB.write(table_name='before_1', path=fname_db, data=before_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79a4f241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file\n",
    "df = DB.fetch(table_name='before_1', path=fname_db)\n",
    "df.columns = col_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "553b241c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-22 16:29:49.278] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:29:51.125] [INFO] [api:fetch:236] Fetched 52 tweets\n"
     ]
    }
   ],
   "source": [
    "# gpt-1 after\n",
    "target_total = 30000\n",
    "keyword = 'gpt'\n",
    "start_date = '2018-06-12'   \n",
    "end_date = '2018-06-15'\n",
    "retweets = False\n",
    "after_1 = History.fetch(keyword=keyword, start_date= start_date, end_date= end_date, \n",
    "                    target_total=target_total, retweets=retweets) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "894270d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-22 16:30:29.200] [INFO] [api:write:61] Writing 152 rows to table after_1\n"
     ]
    }
   ],
   "source": [
    "# write file\n",
    "fname_db = f\"data/esther\"  \n",
    "DB.write(table_name='after_1', path=fname_db, data=after_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4eb5b08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-22 16:31:42.738] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:31:44.335] [INFO] [api:fetch:236] Fetched 38 tweets\n"
     ]
    }
   ],
   "source": [
    "# gpt-2 before\n",
    "target_total = 30000\n",
    "keyword = 'gpt'\n",
    "start_date = '2019-02-11'   \n",
    "end_date = '2019-02-14'\n",
    "retweets = False\n",
    "before_2 = History.fetch(keyword=keyword, start_date= start_date, end_date= end_date, \n",
    "                    target_total=target_total, retweets=retweets) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06e86df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-22 16:32:36.590] [INFO] [api:write:61] Writing 136 rows to table before_2\n"
     ]
    }
   ],
   "source": [
    "# write file\n",
    "fname_db = f\"data/esther\"  \n",
    "DB.write(table_name='before_2', path=fname_db, data=before_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "009f797a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-22 16:33:18.892] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:33:20.940] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:33:22.683] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:33:24.416] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:33:26.398] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:33:28.307] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:33:30.165] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:33:31.755] [INFO] [api:fetch:236] Fetched 15 tweets\n"
     ]
    }
   ],
   "source": [
    "# gpt-2 after\n",
    "target_total = 30000\n",
    "keyword = 'gpt'\n",
    "start_date = '2019-02-15'   \n",
    "end_date = '2019-02-18'\n",
    "retweets = False\n",
    "after_2 = History.fetch(keyword=keyword, start_date= start_date, end_date= end_date, \n",
    "                    target_total=target_total, retweets=retweets) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "19a2a4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-22 16:34:02.169] [INFO] [api:write:61] Writing 711 rows to table after_2\n"
     ]
    }
   ],
   "source": [
    "# write file\n",
    "fname_db = f\"data/esther\"  \n",
    "DB.write(table_name='after_2', path=fname_db, data=after_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f5df0281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-22 16:35:09.681] [INFO] [api:fetch:236] Fetched 93 tweets\n",
      "[2023-04-22 16:35:11.533] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 16:35:13.369] [INFO] [api:fetch:236] Fetched 90 tweets\n"
     ]
    }
   ],
   "source": [
    "# gpt-3 before\n",
    "target_total = 30000\n",
    "keyword = 'gpt'\n",
    "start_date = '2020-06-08'   \n",
    "end_date = '2020-06-11'\n",
    "retweets = False\n",
    "before_3 = History.fetch(keyword=keyword, start_date= start_date, end_date= end_date, \n",
    "                    target_total=target_total, retweets=retweets) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c33a2c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-22 16:35:44.902] [INFO] [api:write:61] Writing 278 rows to table before_3\n"
     ]
    }
   ],
   "source": [
    "# write file\n",
    "fname_db = f\"data/esther\"  \n",
    "DB.write(table_name='before_3', path=fname_db, data=before_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c2e73b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-22 16:36:24.841] [INFO] [api:fetch:236] Fetched 92 tweets\n",
      "[2023-04-22 16:36:26.685] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:36:28.329] [INFO] [api:fetch:236] Fetched 92 tweets\n",
      "[2023-04-22 16:36:29.968] [INFO] [api:fetch:236] Fetched 60 tweets\n"
     ]
    }
   ],
   "source": [
    "# gpt-3 after\n",
    "target_total = 30000\n",
    "keyword = 'gpt'\n",
    "start_date = '2020-06-12'   \n",
    "end_date = '2020-06-15'\n",
    "retweets = False\n",
    "after_3 = History.fetch(keyword=keyword, start_date= start_date, end_date= end_date, \n",
    "                    target_total=target_total, retweets=retweets) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a53fed22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-22 16:37:10.416] [INFO] [api:write:61] Writing 342 rows to table after_3\n"
     ]
    }
   ],
   "source": [
    "# write file\n",
    "fname_db = f\"data/esther\"  \n",
    "DB.write(table_name='after_3', path=fname_db, data=after_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bcf161c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-22 16:37:53.321] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:37:55.160] [INFO] [api:fetch:236] Fetched 92 tweets\n",
      "[2023-04-22 16:37:56.801] [INFO] [api:fetch:236] Fetched 92 tweets\n",
      "[2023-04-22 16:37:58.503] [INFO] [api:fetch:236] Fetched 30 tweets\n"
     ]
    }
   ],
   "source": [
    "# gpt-3.5 before\n",
    "target_total = 30000\n",
    "keyword = 'gpt'\n",
    "start_date = '2022-03-12'   \n",
    "end_date = '2022-03-15'\n",
    "retweets = False\n",
    "before_35 = History.fetch(keyword=keyword, start_date= start_date, end_date= end_date, \n",
    "                    target_total=target_total, retweets=retweets) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8f61312e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-22 16:38:59.353] [INFO] [api:write:61] Writing 313 rows to table before_35\n"
     ]
    }
   ],
   "source": [
    "# write file\n",
    "fname_db = f\"data/esther\"  \n",
    "DB.write(table_name='before_35', path=fname_db, data=before_35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1adeef10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-22 16:39:49.316] [INFO] [api:fetch:236] Fetched 92 tweets\n",
      "[2023-04-22 16:39:51.074] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 16:39:52.924] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:39:54.972] [INFO] [api:fetch:236] Fetched 93 tweets\n",
      "[2023-04-22 16:39:56.602] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:39:58.209] [INFO] [api:fetch:236] Fetched 42 tweets\n"
     ]
    }
   ],
   "source": [
    "# gpt-3.5 after\n",
    "target_total = 30000\n",
    "keyword = 'gpt'\n",
    "start_date = '2022-03-16'   \n",
    "end_date = '2022-03-19'\n",
    "retweets = False\n",
    "after_35 = History.fetch(keyword=keyword, start_date= start_date, end_date= end_date, \n",
    "                    target_total=target_total, retweets=retweets) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "68b8116c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-22 16:40:29.089] [INFO] [api:write:61] Writing 516 rows to table after_35\n"
     ]
    }
   ],
   "source": [
    "# write file\n",
    "fname_db = f\"data/esther\"  \n",
    "DB.write(table_name='after_35', path=fname_db, data=after_35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b35f2ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-22 16:41:11.356] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:41:13.203] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:41:15.053] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 16:41:16.900] [INFO] [api:fetch:236] Fetched 94 tweets\n",
      "[2023-04-22 16:41:18.763] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 16:41:20.595] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:41:22.440] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:41:24.289] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:41:26.139] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:41:27.771] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 16:41:29.614] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:41:31.460] [INFO] [api:fetch:236] Fetched 93 tweets\n",
      "[2023-04-22 16:41:33.154] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:41:34.707] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:41:36.302] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:41:37.987] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:41:39.625] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:41:41.258] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:41:42.905] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:41:44.702] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:41:46.625] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:41:48.478] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:41:50.517] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 16:41:52.366] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:41:54.209] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:41:56.048] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:41:57.891] [INFO] [api:fetch:236] Fetched 94 tweets\n",
      "[2023-04-22 16:41:59.743] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 16:42:01.373] [INFO] [api:fetch:236] Fetched 90 tweets\n",
      "[2023-04-22 16:42:03.270] [INFO] [api:fetch:236] Fetched 94 tweets\n",
      "[2023-04-22 16:42:04.999] [INFO] [api:fetch:236] Fetched 93 tweets\n",
      "[2023-04-22 16:42:06.913] [INFO] [api:fetch:236] Fetched 88 tweets\n",
      "[2023-04-22 16:42:08.754] [INFO] [api:fetch:236] Fetched 82 tweets\n",
      "[2023-04-22 16:42:10.795] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 16:42:12.643] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:42:14.482] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:42:16.330] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:42:18.176] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:42:19.947] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:42:21.683] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:42:23.493] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:42:25.338] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:42:27.188] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:42:29.030] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:42:31.897] [INFO] [api:fetch:236] Fetched 88 tweets\n",
      "[2023-04-22 16:42:33.733] [INFO] [api:fetch:236] Fetched 87 tweets\n",
      "[2023-04-22 16:42:35.376] [INFO] [api:fetch:236] Fetched 88 tweets\n",
      "[2023-04-22 16:42:37.222] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:42:39.057] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:42:40.909] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:42:42.872] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:42:44.590] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 16:42:46.434] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:42:48.070] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:42:49.698] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:42:51.560] [INFO] [api:fetch:236] Fetched 93 tweets\n",
      "[2023-04-22 16:42:53.396] [INFO] [api:fetch:236] Fetched 92 tweets\n",
      "[2023-04-22 16:42:55.028] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 16:42:56.884] [INFO] [api:fetch:236] Fetched 92 tweets\n",
      "[2023-04-22 16:42:58.692] [INFO] [api:fetch:236] Fetched 92 tweets\n",
      "[2023-04-22 16:43:00.407] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 16:43:02.202] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:43:04.661] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:43:06.503] [INFO] [api:fetch:236] Fetched 93 tweets\n",
      "[2023-04-22 16:43:08.348] [INFO] [api:fetch:236] Fetched 94 tweets\n",
      "[2023-04-22 16:43:10.053] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 16:43:11.753] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:43:13.462] [INFO] [api:fetch:236] Fetched 93 tweets\n",
      "[2023-04-22 16:43:15.109] [INFO] [api:fetch:236] Fetched 93 tweets\n",
      "[2023-04-22 16:43:16.948] [INFO] [api:fetch:236] Fetched 93 tweets\n",
      "[2023-04-22 16:43:18.799] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:43:20.638] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 16:43:22.486] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:43:24.273] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:43:25.953] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 16:43:27.800] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 16:43:29.850] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:43:31.694] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:43:33.540] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:43:35.380] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:43:37.017] [INFO] [api:fetch:236] Fetched 93 tweets\n",
      "[2023-04-22 16:43:38.877] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:43:40.915] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 16:43:42.589] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 16:43:44.397] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:43:46.439] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 16:43:48.082] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:43:49.713] [INFO] [api:fetch:236] Fetched 85 tweets\n",
      "[2023-04-22 16:43:51.320] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:43:53.163] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:43:54.801] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:43:56.473] [INFO] [api:fetch:236] Fetched 92 tweets\n",
      "[2023-04-22 16:43:58.307] [INFO] [api:fetch:236] Fetched 90 tweets\n",
      "[2023-04-22 16:44:00.160] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:44:01.798] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:44:03.647] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:44:05.326] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:44:07.124] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:44:09.172] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:44:11.014] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:44:12.865] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 16:44:14.704] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 16:44:16.750] [INFO] [api:fetch:236] Fetched 92 tweets\n",
      "[2023-04-22 16:44:18.509] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 16:44:20.132] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:44:22.041] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:44:23.678] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:44:25.522] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:44:27.606] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 16:44:29.453] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:44:31.298] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:44:33.141] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:44:34.976] [INFO] [api:fetch:236] Fetched 94 tweets\n",
      "[2023-04-22 16:44:36.822] [INFO] [api:fetch:236] Fetched 94 tweets\n",
      "[2023-04-22 16:44:38.670] [INFO] [api:fetch:236] Fetched 90 tweets\n",
      "[2023-04-22 16:44:40.526] [INFO] [api:fetch:236] Fetched 94 tweets\n",
      "[2023-04-22 16:44:42.356] [INFO] [api:fetch:236] Fetched 87 tweets\n",
      "[2023-04-22 16:44:44.007] [INFO] [api:fetch:236] Fetched 77 tweets\n",
      "[2023-04-22 16:44:45.838] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 16:44:47.675] [INFO] [api:fetch:236] Fetched 92 tweets\n",
      "[2023-04-22 16:44:49.517] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 16:44:51.358] [INFO] [api:fetch:236] Fetched 93 tweets\n",
      "[2023-04-22 16:44:53.054] [INFO] [api:fetch:236] Fetched 99 tweets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-22 16:44:54.849] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 16:44:56.686] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:44:58.528] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:45:00.586] [INFO] [api:fetch:236] Fetched 88 tweets\n",
      "[2023-04-22 16:45:02.417] [INFO] [api:fetch:236] Fetched 93 tweets\n",
      "[2023-04-22 16:45:04.266] [INFO] [api:fetch:236] Fetched 85 tweets\n",
      "[2023-04-22 16:45:06.115] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 16:45:07.949] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:45:09.802] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 16:45:11.642] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 16:45:13.684] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:45:15.328] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 16:45:17.190] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 16:45:18.810] [INFO] [api:fetch:236] Fetched 93 tweets\n",
      "[2023-04-22 16:45:20.518] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:45:22.252] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:45:23.890] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:45:25.775] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 16:45:27.583] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:45:29.664] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:45:31.503] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 16:45:33.204] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:45:34.983] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:45:36.811] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 16:45:38.674] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 16:45:40.518] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:45:42.352] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:45:44.128] [INFO] [api:fetch:236] Fetched 94 tweets\n",
      "[2023-04-22 16:45:45.838] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:45:48.001] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:45:50.014] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:45:51.787] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:45:53.619] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:45:55.465] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 16:45:57.143] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 16:45:58.990] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:46:00.794] [INFO] [api:fetch:236] Fetched 94 tweets\n",
      "[2023-04-22 16:46:02.639] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 16:46:04.473] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 16:46:06.318] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:46:08.163] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:46:10.011] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:46:12.054] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:46:13.783] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 16:46:15.534] [INFO] [api:fetch:236] Fetched 92 tweets\n",
      "[2023-04-22 16:46:17.389] [INFO] [api:fetch:236] Fetched 87 tweets\n",
      "[2023-04-22 16:46:19.431] [INFO] [api:fetch:236] Fetched 93 tweets\n",
      "[2023-04-22 16:46:21.249] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:46:22.873] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:46:24.512] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:46:26.150] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:46:27.990] [INFO] [api:fetch:236] Fetched 94 tweets\n",
      "[2023-04-22 16:46:29.631] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:46:31.475] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:46:33.114] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:46:34.998] [INFO] [api:fetch:236] Fetched 92 tweets\n",
      "[2023-04-22 16:46:36.842] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:46:38.686] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:46:40.938] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:46:42.720] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 16:46:44.575] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:46:46.467] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:46:48.514] [INFO] [api:fetch:236] Fetched 69 tweets\n"
     ]
    }
   ],
   "source": [
    "# gpt-4 before\n",
    "target_total = 30000\n",
    "keyword = 'gpt'\n",
    "start_date = '2023-03-11'   \n",
    "end_date = '2023-03-14'\n",
    "retweets = False\n",
    "before_4 = History.fetch(keyword=keyword, start_date= start_date, end_date= end_date, \n",
    "                    target_total=target_total, retweets=retweets) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e225d936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-22 16:47:41.108] [INFO] [api:write:61] Writing 17844 rows to table before_4\n"
     ]
    }
   ],
   "source": [
    "# write file\n",
    "fname_db = f\"data/esther\"  \n",
    "DB.write(table_name='before_4', path=fname_db, data=before_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "45968f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>geo</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-13T23:59:15.000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>@_donghyuck_ What if I put your tweet into Chat gpt and let it write that</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1635430352339468289</td>\n",
       "      <td>2754555103</td>\n",
       "      <td>1635387599568379905</td>\n",
       "      <td>932442537591296000</td>\n",
       "      <td>nan</td>\n",
       "      <td>{'mentions': [{'start': 0, 'end': 12, 'username': '_donghyuck_', 'id': '932442537591296000'}]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-13T23:58:58.000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>@followmarcos @nickfloats @LinusEkenstam @Jerry_HZN Mind-blowing. Can chat gpt create prompts for different lighting, camera, angles etc.?</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1635430279438389252</td>\n",
       "      <td>1606053994081796096</td>\n",
       "      <td>1635270385137770496</td>\n",
       "      <td>1577597236049068034</td>\n",
       "      <td>nan</td>\n",
       "      <td>{'mentions': [{'start': 0, 'end': 13, 'username': 'followmarcos', 'id': '1577597236049068034'}, {'start': 14, 'end': 25, 'username': 'nickfloats', 'id': '146358342'}, {'start': 26, 'end': 40, 'username': 'LinusEkenstam', 'id': '3888491'}, {'start': 41, 'end': 51, 'username': 'Jerry_HZN', 'id': '932820597444366336'}]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-13T23:58:07.000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>Where my 1000 $GPT? https://t.co/PieaRYuP9c</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1635430066586009600</td>\n",
       "      <td>64590354</td>\n",
       "      <td>1635430066586009600</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>{'urls': [{'start': 20, 'end': 43, 'url': 'https://t.co/PieaRYuP9c', 'expanded_url': 'https://twitter.com/SpaceIDAirdrops/status/1635394365412757504', 'display_url': 'twitter.com/SpaceIDAirdrop…'}], 'annotations': [{'start': 15, 'end': 17, 'probability': 0.5635, 'type': 'Organization', 'normalized_text': 'GPT'}], 'cashtags': [{'start': 14, 'end': 18, 'tag': 'GPT'}]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-13T23:57:47.000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>Stop putting GPT in your product name 😅</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1635429983781896195</td>\n",
       "      <td>939861245670383616</td>\n",
       "      <td>1635429983781896195</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>{'annotations': [{'start': 13, 'end': 15, 'probability': 0.6508, 'type': 'Other', 'normalized_text': 'GPT'}]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-13T23:57:44.000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>@Al_CryptoGPT ez $GPT!</td>\n",
       "      <td>und</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1635429972088090625</td>\n",
       "      <td>1465544898</td>\n",
       "      <td>1635423885742034956</td>\n",
       "      <td>2909683096</td>\n",
       "      <td>nan</td>\n",
       "      <td>{'cashtags': [{'start': 17, 'end': 21, 'tag': 'GPT'}]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2023-03-11T00:01:10.000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>$350 USD per Ethereum is high...Especially when compared with a new niche like GPT or parent OpenAI, all of the above make promises \"to change the world\", new tech need minimum 20 year development and testing before cashflow https://t.co/tTfyyiLxHQ</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1634343672342024193</td>\n",
       "      <td>19398617</td>\n",
       "      <td>1634343672342024193</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>{'annotations': [{'start': 13, 'end': 20, 'probability': 0.6886, 'type': 'Other', 'normalized_text': 'Ethereum'}, {'start': 79, 'end': 81, 'probability': 0.5981, 'type': 'Other', 'normalized_text': 'GPT'}, {'start': 93, 'end': 98, 'probability': 0.5517, 'type': 'Other', 'normalized_text': 'OpenAI'}], 'urls': [{'start': 225, 'end': 248, 'url': 'https://t.co/tTfyyiLxHQ', 'expanded_url': 'https://twitter.com/CitronResearch/status/1634168374623191040', 'display_url': 'twitter.com/CitronResearch…'}]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2023-03-11T00:01:00.000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>As colleges around the country prepare for assessment season, students and lecturers are facing major challenges due to the rise of AI software like ChatGPT, which can produce essays in seconds https://t.co/slyjxxXzw2</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1634343628351889412</td>\n",
       "      <td>150246405</td>\n",
       "      <td>1634343628351889412</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>{'annotations': [{'start': 132, 'end': 133, 'probability': 0.62, 'type': 'Organization', 'normalized_text': 'AI'}, {'start': 149, 'end': 155, 'probability': 0.84, 'type': 'Other', 'normalized_text': 'ChatGPT'}], 'urls': [{'start': 194, 'end': 217, 'url': 'https://t.co/slyjxxXzw2', 'expanded_url': 'http://jrnl.ie/6013726t', 'display_url': 'jrnl.ie/6013726t', 'images': [{'url': 'https://pbs.twimg.com/news_img/1639660116126449668/TyKS2dzm?format=jpg&amp;name=orig', 'width': 590, 'height': 393}, {'url': 'https://pbs.twimg.com/news_img/1639660116126449668/TyKS2dzm?format=jpg&amp;name=150x150', 'width': 150, 'height': 150}], 'status': 200, 'title': 'With the rise of ChatGPT, how are universities planning on assessing students this year?', 'description': 'The software can produce essays on almost any topic in seconds, causing worry among colleges about academic integrity.', 'unwound_url': 'https://www.thejournal.ie/chat-gpt-college-assessment-exams-6013726-Mar2023/?utm_source=twitter_short'}]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2023-03-11T00:00:58.000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>If this does what it says on the tin, it has amazimg opportunities to improve horizon scanning. I already built the data collection system but need this development to extract data from web. i could not find a similar service up…https://t.co/SQbQoG7YJI https://t.co/f45IZUA60l</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1634343622505291777</td>\n",
       "      <td>8156732</td>\n",
       "      <td>1634343622505291777</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>{'annotations': [{'start': 78, 'end': 84, 'probability': 0.6819, 'type': 'Other', 'normalized_text': 'horizon'}], 'urls': [{'start': 229, 'end': 252, 'url': 'https://t.co/SQbQoG7YJI', 'expanded_url': 'https://lnkd.in/ehmPXAUT', 'display_url': 'lnkd.in/ehmPXAUT', 'images': [{'url': 'https://pbs.twimg.com/news_img/1634343627731382272/MZbIM8Jl?format=jpg&amp;name=orig', 'width': 500, 'height': 334}, {'url': 'https://pbs.twimg.com/news_img/1634343627731382272/MZbIM8Jl?format=jpg&amp;name=150x150', 'width': 150, 'height': 150}], 'status': 200, 'title': \"Michael Jackson on LinkedIn: OpenAI's GPT-4 to 'launch next week' - Microsoft Germany\", 'description': 'https://lnkd.in/ergbkRja If this does what it says on the tin, it has amazimg opportunities to improve horizon scanning. I already built the data collection…', 'unwound_url': 'https://www.linkedin.com/feed/update/urn:li:share:7040109247723896832'}, {'start': 253, 'end': 276, 'url': 'https://t.co/f45IZUA60l', 'expanded_url': 'https://lnkd.in/ergbkRja', 'display_url': 'lnkd.in/ergbkRja', 'images': [{'url': 'https://pbs.twimg.com/news_img/1638428994474213377/pEKQofIR?format=jpg&amp;name=orig', 'width': 500, 'height': 334}, {'url': 'https://pbs.twimg.com/news_img/1638428994474213377/pEKQofIR?format=jpg&amp;name=150x150', 'width': 150, 'height': 150}], 'status': 200, 'title': \"OpenAI's GPT-4 to 'launch next week' - Microsoft Germany\", 'description': \"Rumours about ChatGPT maker OpenAI's next large language AI model have been swirling for some time. We may not have much longer to wait.\", 'unwound_url': 'https://techmonitor.ai/technology/ai-and-automation/gpt-4-openai-microsoft-chatgpt'}]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2023-03-11T00:00:55.000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>The SVB crisis well it's not like we could have seen it coming but it was pretty clear that the aliens/time travelers/Illuminati were going to put their foot on the brakes in some way with GPT-4 coming out. One startup that would have gotten funded &amp;amp; launched singularity too soon</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1634343606688563201</td>\n",
       "      <td>13143952</td>\n",
       "      <td>1634343606688563201</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>{'annotations': [{'start': 4, 'end': 6, 'probability': 0.8363, 'type': 'Other', 'normalized_text': 'SVB'}, {'start': 118, 'end': 127, 'probability': 0.512, 'type': 'Other', 'normalized_text': 'Illuminati'}, {'start': 189, 'end': 193, 'probability': 0.8397, 'type': 'Other', 'normalized_text': 'GPT-4'}]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2023-03-11T00:00:15.000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>@iramadisonthree Chat GPT</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1634343438916419584</td>\n",
       "      <td>165918859</td>\n",
       "      <td>1634249306570891271</td>\n",
       "      <td>1483255232855478272</td>\n",
       "      <td>nan</td>\n",
       "      <td>{'mentions': [{'start': 0, 'end': 16, 'username': 'iramadisonthree', 'id': '1483255232855478272'}]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17844 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  created_at screen_name  \\\n",
       "0   2023-03-13T23:59:15.000Z        None   \n",
       "1   2023-03-13T23:58:58.000Z        None   \n",
       "2   2023-03-13T23:58:07.000Z        None   \n",
       "3   2023-03-13T23:57:47.000Z        None   \n",
       "4   2023-03-13T23:57:44.000Z        None   \n",
       "..                       ...         ...   \n",
       "64  2023-03-11T00:01:10.000Z        None   \n",
       "65  2023-03-11T00:01:00.000Z        None   \n",
       "66  2023-03-11T00:00:58.000Z        None   \n",
       "67  2023-03-11T00:00:55.000Z        None   \n",
       "68  2023-03-11T00:00:15.000Z        None   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                            text  \\\n",
       "0                                                                                                                                                                                                                      @_donghyuck_ What if I put your tweet into Chat gpt and let it write that   \n",
       "1                                                                                                                                                     @followmarcos @nickfloats @LinusEkenstam @Jerry_HZN Mind-blowing. Can chat gpt create prompts for different lighting, camera, angles etc.?   \n",
       "2                                                                                                                                                                                                                                                    Where my 1000 $GPT? https://t.co/PieaRYuP9c   \n",
       "3                                                                                                                                                                                                                                                        Stop putting GPT in your product name 😅   \n",
       "4                                                                                                                                                                                                                                                                         @Al_CryptoGPT ez $GPT!   \n",
       "..                                                                                                                                                                                                                                                                                           ...   \n",
       "64                                      $350 USD per Ethereum is high...Especially when compared with a new niche like GPT or parent OpenAI, all of the above make promises \"to change the world\", new tech need minimum 20 year development and testing before cashflow https://t.co/tTfyyiLxHQ   \n",
       "65                                                                     As colleges around the country prepare for assessment season, students and lecturers are facing major challenges due to the rise of AI software like ChatGPT, which can produce essays in seconds https://t.co/slyjxxXzw2   \n",
       "66          If this does what it says on the tin, it has amazimg opportunities to improve horizon scanning. I already built the data collection system but need this development to extract data from web. i could not find a similar service up…https://t.co/SQbQoG7YJI https://t.co/f45IZUA60l   \n",
       "67  The SVB crisis well it's not like we could have seen it coming but it was pretty clear that the aliens/time travelers/Illuminati were going to put their foot on the brakes in some way with GPT-4 coming out. One startup that would have gotten funded &amp; launched singularity too soon   \n",
       "68                                                                                                                                                                                                                                                                     @iramadisonthree Chat GPT   \n",
       "\n",
       "   lang  retweet_count  reply_count  like_count  quote_count  \\\n",
       "0    en              0            1           0            0   \n",
       "1    en              0            1           1            0   \n",
       "2    en              0            0           1            0   \n",
       "3    en              0            0           0            0   \n",
       "4   und              0            0           0            0   \n",
       "..  ...            ...          ...         ...          ...   \n",
       "64   en              0            0           0            0   \n",
       "65   en              1            0           9            1   \n",
       "66   en              0            0           1            0   \n",
       "67   en              0            0           3            0   \n",
       "68   en              0            0           3            0   \n",
       "\n",
       "                     id            author_id      conversation_id  \\\n",
       "0   1635430352339468289           2754555103  1635387599568379905   \n",
       "1   1635430279438389252  1606053994081796096  1635270385137770496   \n",
       "2   1635430066586009600             64590354  1635430066586009600   \n",
       "3   1635429983781896195   939861245670383616  1635429983781896195   \n",
       "4   1635429972088090625           1465544898  1635423885742034956   \n",
       "..                  ...                  ...                  ...   \n",
       "64  1634343672342024193             19398617  1634343672342024193   \n",
       "65  1634343628351889412            150246405  1634343628351889412   \n",
       "66  1634343622505291777              8156732  1634343622505291777   \n",
       "67  1634343606688563201             13143952  1634343606688563201   \n",
       "68  1634343438916419584            165918859  1634249306570891271   \n",
       "\n",
       "    in_reply_to_user_id  geo  \\\n",
       "0    932442537591296000  nan   \n",
       "1   1577597236049068034  nan   \n",
       "2                   nan  nan   \n",
       "3                   nan  nan   \n",
       "4            2909683096  nan   \n",
       "..                  ...  ...   \n",
       "64                  nan  nan   \n",
       "65                  nan  nan   \n",
       "66                  nan  nan   \n",
       "67                  nan  nan   \n",
       "68  1483255232855478272  nan   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    entities  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             {'mentions': [{'start': 0, 'end': 12, 'username': '_donghyuck_', 'id': '932442537591296000'}]}  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             {'mentions': [{'start': 0, 'end': 13, 'username': 'followmarcos', 'id': '1577597236049068034'}, {'start': 14, 'end': 25, 'username': 'nickfloats', 'id': '146358342'}, {'start': 26, 'end': 40, 'username': 'LinusEkenstam', 'id': '3888491'}, {'start': 41, 'end': 51, 'username': 'Jerry_HZN', 'id': '932820597444366336'}]}  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           {'urls': [{'start': 20, 'end': 43, 'url': 'https://t.co/PieaRYuP9c', 'expanded_url': 'https://twitter.com/SpaceIDAirdrops/status/1635394365412757504', 'display_url': 'twitter.com/SpaceIDAirdrop…'}], 'annotations': [{'start': 15, 'end': 17, 'probability': 0.5635, 'type': 'Organization', 'normalized_text': 'GPT'}], 'cashtags': [{'start': 14, 'end': 18, 'tag': 'GPT'}]}  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              {'annotations': [{'start': 13, 'end': 15, 'probability': 0.6508, 'type': 'Other', 'normalized_text': 'GPT'}]}  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     {'cashtags': [{'start': 17, 'end': 21, 'tag': 'GPT'}]}  \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ...  \n",
       "64                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      {'annotations': [{'start': 13, 'end': 20, 'probability': 0.6886, 'type': 'Other', 'normalized_text': 'Ethereum'}, {'start': 79, 'end': 81, 'probability': 0.5981, 'type': 'Other', 'normalized_text': 'GPT'}, {'start': 93, 'end': 98, 'probability': 0.5517, 'type': 'Other', 'normalized_text': 'OpenAI'}], 'urls': [{'start': 225, 'end': 248, 'url': 'https://t.co/tTfyyiLxHQ', 'expanded_url': 'https://twitter.com/CitronResearch/status/1634168374623191040', 'display_url': 'twitter.com/CitronResearch…'}]}  \n",
       "65                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         {'annotations': [{'start': 132, 'end': 133, 'probability': 0.62, 'type': 'Organization', 'normalized_text': 'AI'}, {'start': 149, 'end': 155, 'probability': 0.84, 'type': 'Other', 'normalized_text': 'ChatGPT'}], 'urls': [{'start': 194, 'end': 217, 'url': 'https://t.co/slyjxxXzw2', 'expanded_url': 'http://jrnl.ie/6013726t', 'display_url': 'jrnl.ie/6013726t', 'images': [{'url': 'https://pbs.twimg.com/news_img/1639660116126449668/TyKS2dzm?format=jpg&name=orig', 'width': 590, 'height': 393}, {'url': 'https://pbs.twimg.com/news_img/1639660116126449668/TyKS2dzm?format=jpg&name=150x150', 'width': 150, 'height': 150}], 'status': 200, 'title': 'With the rise of ChatGPT, how are universities planning on assessing students this year?', 'description': 'The software can produce essays on almost any topic in seconds, causing worry among colleges about academic integrity.', 'unwound_url': 'https://www.thejournal.ie/chat-gpt-college-assessment-exams-6013726-Mar2023/?utm_source=twitter_short'}]}  \n",
       "66  {'annotations': [{'start': 78, 'end': 84, 'probability': 0.6819, 'type': 'Other', 'normalized_text': 'horizon'}], 'urls': [{'start': 229, 'end': 252, 'url': 'https://t.co/SQbQoG7YJI', 'expanded_url': 'https://lnkd.in/ehmPXAUT', 'display_url': 'lnkd.in/ehmPXAUT', 'images': [{'url': 'https://pbs.twimg.com/news_img/1634343627731382272/MZbIM8Jl?format=jpg&name=orig', 'width': 500, 'height': 334}, {'url': 'https://pbs.twimg.com/news_img/1634343627731382272/MZbIM8Jl?format=jpg&name=150x150', 'width': 150, 'height': 150}], 'status': 200, 'title': \"Michael Jackson on LinkedIn: OpenAI's GPT-4 to 'launch next week' - Microsoft Germany\", 'description': 'https://lnkd.in/ergbkRja If this does what it says on the tin, it has amazimg opportunities to improve horizon scanning. I already built the data collection…', 'unwound_url': 'https://www.linkedin.com/feed/update/urn:li:share:7040109247723896832'}, {'start': 253, 'end': 276, 'url': 'https://t.co/f45IZUA60l', 'expanded_url': 'https://lnkd.in/ergbkRja', 'display_url': 'lnkd.in/ergbkRja', 'images': [{'url': 'https://pbs.twimg.com/news_img/1638428994474213377/pEKQofIR?format=jpg&name=orig', 'width': 500, 'height': 334}, {'url': 'https://pbs.twimg.com/news_img/1638428994474213377/pEKQofIR?format=jpg&name=150x150', 'width': 150, 'height': 150}], 'status': 200, 'title': \"OpenAI's GPT-4 to 'launch next week' - Microsoft Germany\", 'description': \"Rumours about ChatGPT maker OpenAI's next large language AI model have been swirling for some time. We may not have much longer to wait.\", 'unwound_url': 'https://techmonitor.ai/technology/ai-and-automation/gpt-4-openai-microsoft-chatgpt'}]}  \n",
       "67                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           {'annotations': [{'start': 4, 'end': 6, 'probability': 0.8363, 'type': 'Other', 'normalized_text': 'SVB'}, {'start': 118, 'end': 127, 'probability': 0.512, 'type': 'Other', 'normalized_text': 'Illuminati'}, {'start': 189, 'end': 193, 'probability': 0.8397, 'type': 'Other', 'normalized_text': 'GPT-4'}]}  \n",
       "68                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       {'mentions': [{'start': 0, 'end': 16, 'username': 'iramadisonthree', 'id': '1483255232855478272'}]}  \n",
       "\n",
       "[17844 rows x 14 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5fd13da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-22 16:48:43.617] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:48:45.450] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:48:47.236] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:48:49.135] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:48:50.985] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:48:52.827] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:48:54.504] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:48:56.311] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:48:58.150] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:48:59.998] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:49:02.048] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:49:04.095] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:49:05.905] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:49:07.816] [INFO] [api:fetch:236] Fetched 94 tweets\n",
      "[2023-04-22 16:49:09.849] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:49:11.697] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:49:13.738] [INFO] [api:fetch:236] Fetched 93 tweets\n",
      "[2023-04-22 16:49:15.792] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:49:17.619] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:49:19.454] [INFO] [api:fetch:236] Fetched 93 tweets\n",
      "[2023-04-22 16:49:21.326] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:49:23.166] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 16:49:25.005] [INFO] [api:fetch:236] Fetched 93 tweets\n",
      "[2023-04-22 16:49:26.849] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 16:49:28.714] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:49:30.540] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:49:32.394] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:49:34.224] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:49:36.066] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 16:49:37.924] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:49:39.656] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 16:49:41.527] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:49:43.415] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:49:45.157] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:49:47.101] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:49:49.142] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:49:50.992] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:49:52.827] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:49:54.682] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:49:56.529] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 16:49:58.370] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:50:00.209] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 16:50:02.046] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:50:04.133] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:50:06.143] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:50:08.025] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:50:09.787] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:50:11.883] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:50:14.331] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:50:16.182] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 16:50:18.028] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:50:19.975] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:50:21.713] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:50:23.558] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:50:25.397] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:50:27.110] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:50:29.086] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:50:30.929] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:50:32.972] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:50:34.822] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:50:37.067] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:50:38.920] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:50:40.763] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:50:42.606] [INFO] [api:fetch:236] Fetched 94 tweets\n",
      "[2023-04-22 16:50:44.445] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:50:46.236] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:50:47.920] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:50:49.557] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:50:51.217] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:50:53.149] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:50:55.094] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:50:56.929] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:50:58.788] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:51:00.450] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:51:02.153] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:51:04.101] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:51:05.943] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:51:07.788] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:51:09.642] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:51:11.479] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:51:13.319] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:51:15.158] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:51:17.011] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:51:18.851] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:51:20.699] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:51:22.532] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:51:24.376] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:51:26.221] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:51:28.205] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 16:51:30.321] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:51:32.041] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:51:34.008] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:51:35.645] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:51:37.894] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:51:39.642] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:51:41.439] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:51:43.165] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:51:44.857] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 16:51:46.690] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:51:48.547] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:51:50.397] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:51:52.229] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:51:54.009] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:51:55.709] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:51:57.769] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:51:59.601] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:52:01.452] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:52:03.086] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:52:04.930] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:52:06.778] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:52:08.617] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:52:10.263] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:52:12.101] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:52:13.937] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:52:15.791] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:52:17.626] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:52:19.464] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:52:21.309] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:52:22.955] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:52:24.871] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:52:26.643] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:52:28.692] [INFO] [api:fetch:236] Fetched 99 tweets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-22 16:52:30.537] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:52:32.369] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:52:34.215] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:52:36.063] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 16:52:37.905] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 16:52:39.707] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:52:41.592] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:52:43.436] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:52:45.276] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:52:47.031] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:52:48.970] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:52:50.698] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:52:53.268] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:52:55.103] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:52:56.953] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:52:58.801] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:53:00.618] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:53:02.476] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:53:04.327] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:53:06.167] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:53:07.906] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:53:09.856] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:53:11.702] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:53:13.752] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:53:15.584] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:53:17.431] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:53:19.272] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 16:53:21.021] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:53:22.866] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:53:24.699] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:53:26.540] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:53:28.595] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:53:30.431] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:53:32.487] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 16:53:34.271] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:53:36.174] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:53:38.015] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:53:40.068] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:53:41.915] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:53:43.742] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:53:45.592] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:53:47.441] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:53:49.273] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:53:51.122] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:53:52.961] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:53:54.803] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:53:56.846] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:53:58.805] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:54:00.632] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:54:02.482] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:54:04.335] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 16:54:06.170] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:54:08.020] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:54:09.854] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:54:11.677] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:54:13.543] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:54:15.389] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:54:17.235] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:54:19.283] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 16:54:21.126] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:54:23.386] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:54:25.218] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:54:26.862] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:54:28.806] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:54:30.578] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:54:32.486] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:54:34.333] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:54:36.178] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:54:38.222] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:54:40.063] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:54:41.911] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:54:43.667] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:54:45.600] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 16:54:47.435] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:54:49.282] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 16:54:50.955] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:54:52.764] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:54:54.813] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:54:56.652] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:54:58.323] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:55:00.136] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:55:01.978] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:55:03.826] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:55:05.665] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:55:07.390] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:55:09.339] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 16:55:11.192] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:55:13.244] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:55:15.084] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:55:16.931] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:55:18.774] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:55:20.618] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:55:23.478] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 16:55:25.325] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:55:27.342] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:55:29.420] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 16:55:31.264] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:55:33.107] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:55:34.950] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:55:36.795] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:55:38.639] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:55:40.305] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:55:42.164] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:55:43.898] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:55:45.703] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:55:47.554] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:55:49.286] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:55:51.028] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:55:52.869] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:55:54.716] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:55:56.559] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:55:58.607] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:56:00.444] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:56:02.295] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:56:04.134] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:56:05.982] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:56:07.825] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 16:56:09.665] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:56:11.506] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:56:13.236] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:56:14.971] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:56:17.043] [INFO] [api:fetch:236] Fetched 99 tweets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-22 16:56:18.882] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:56:20.725] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:56:22.566] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:56:24.255] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:56:25.935] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:56:27.543] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 16:56:29.235] [INFO] [api:fetch:236] Fetched 94 tweets\n",
      "[2023-04-22 16:56:30.967] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:56:32.809] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:56:34.654] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:56:36.385] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:56:38.949] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:56:40.671] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:56:42.444] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:56:44.406] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:56:46.117] [INFO] [api:fetch:236] Fetched 92 tweets\n",
      "[2023-04-22 16:56:47.967] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:56:49.639] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:56:51.445] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:56:53.288] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:56:55.129] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:56:56.979] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:56:58.822] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:57:00.667] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:57:02.504] [INFO] [api:fetch:236] Fetched 93 tweets\n",
      "[2023-04-22 16:57:04.348] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:57:06.173] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:57:08.036] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:57:09.826] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:57:11.719] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:57:13.395] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:57:15.200] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:57:17.042] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:57:18.886] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:57:20.745] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:57:22.573] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:57:24.417] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:57:26.259] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:57:28.106] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:57:29.948] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:57:31.801] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:57:33.464] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:57:35.194] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:57:37.116] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:57:38.957] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:57:40.802] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:57:42.620] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:57:44.288] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 16:57:45.937] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:57:47.606] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:57:49.435] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:57:51.250] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:57:53.089] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:57:54.930] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:57:56.778] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 16:57:58.412] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:58:00.260] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:58:02.102] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:58:03.943] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 16:58:05.794] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 16:58:07.629] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 16:58:09.400] [INFO] [api:fetch:236] Fetched 98 tweets\n"
     ]
    }
   ],
   "source": [
    "# gpt-4 after\n",
    "target_total = 30000\n",
    "keyword = 'gpt'\n",
    "start_date = '2023-03-15'   \n",
    "end_date = '2023-03-18'\n",
    "retweets = False\n",
    "after_4 = History.fetch(keyword=keyword, start_date= start_date, end_date= end_date, \n",
    "                    target_total=target_total, retweets=retweets) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9ded8d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df20230317 = after_4[after_4.created_at>'2023-03-17']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8594f618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-22 17:02:07.660] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:02:09.302] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:02:10.933] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:02:12.511] [INFO] [api:fetch:236] Fetched 92 tweets\n",
      "[2023-04-22 17:02:14.216] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:02:15.851] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:02:17.694] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:02:19.330] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:02:20.924] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:02:22.612] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:02:24.249] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:02:25.889] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:02:27.524] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:02:29.131] [INFO] [api:fetch:236] Fetched 91 tweets\n",
      "[2023-04-22 17:02:30.800] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:02:32.437] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:02:34.078] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:02:35.718] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:02:37.562] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:02:39.198] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:02:40.847] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:02:42.568] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:02:44.317] [INFO] [api:fetch:236] Fetched 92 tweets\n",
      "[2023-04-22 17:02:45.959] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:02:47.600] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:02:49.233] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:02:50.872] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:02:52.509] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:02:54.154] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:02:55.786] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:02:57.423] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:02:59.266] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:03:00.853] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:03:02.450] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:03:04.184] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:03:05.823] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:03:07.462] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:03:09.100] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:03:10.739] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:03:12.586] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:03:14.218] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:03:15.838] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:03:17.495] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:03:19.138] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:03:20.774] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:03:22.300] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:03:24.049] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:03:25.692] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:03:27.326] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:03:28.954] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:03:30.596] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:03:32.238] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:03:33.878] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:03:35.518] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:03:37.361] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:03:38.997] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:03:40.639] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:03:42.200] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:03:43.830] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:03:45.760] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:03:47.602] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 17:03:49.652] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:03:51.493] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:03:53.335] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:03:55.180] [INFO] [api:fetch:236] Fetched 91 tweets\n",
      "[2023-04-22 17:03:57.025] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:03:58.866] [INFO] [api:fetch:236] Fetched 88 tweets\n",
      "[2023-04-22 17:04:00.708] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:04:02.553] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 17:04:04.281] [INFO] [api:fetch:236] Fetched 91 tweets\n",
      "[2023-04-22 17:04:06.003] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:04:07.764] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 17:04:09.515] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:04:11.153] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 17:04:12.998] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:04:14.841] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 17:04:16.679] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:04:18.432] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:04:20.165] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:04:22.013] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:04:23.851] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:04:25.096] [INFO] [api:fetch:227] Sleeping\n",
      "[2023-04-22 17:19:27.052] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:19:28.890] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:19:31.349] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:19:33.090] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:19:35.036] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 17:19:36.877] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:19:38.928] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:19:40.771] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:19:42.617] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:19:44.282] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:19:45.972] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:19:47.734] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:19:49.781] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:19:51.611] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:19:53.313] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:19:55.106] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:19:57.101] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:19:58.794] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:20:00.639] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:20:02.477] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:20:04.323] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:20:06.166] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:20:08.822] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:20:10.672] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:20:12.516] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:20:14.214] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:20:15.968] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:20:18.044] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:20:19.888] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:20:22.138] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 17:20:24.187] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:20:26.030] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:20:28.077] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:20:30.428] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:20:32.379] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:20:34.388] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:20:36.272] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:20:38.317] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:20:40.162] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:20:41.900] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:20:43.848] [INFO] [api:fetch:236] Fetched 98 tweets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-22 17:20:46.866] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:20:49.379] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:20:51.426] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:20:53.476] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:20:55.170] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:20:57.160] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:20:59.212] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:21:01.171] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:21:03.520] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:21:05.355] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:21:07.200] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:21:09.245] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:21:11.297] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:21:13.135] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:21:14.978] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:21:16.729] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:21:18.750] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:21:20.719] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:21:22.560] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:21:24.399] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:21:26.244] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:21:28.012] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:21:30.137] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:21:32.181] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:21:34.639] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:21:36.286] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:21:38.328] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:21:40.374] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 17:21:42.090] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 17:21:43.853] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:21:46.319] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:21:48.364] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:21:50.415] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:21:52.256] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:21:53.896] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:21:55.678] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:21:57.577] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:21:59.420] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:22:01.265] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:22:03.107] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 17:22:04.945] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:22:06.797] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:22:08.643] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:22:10.486] [INFO] [api:fetch:236] Fetched 94 tweets\n",
      "[2023-04-22 17:22:12.941] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:22:14.783] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 17:22:17.853] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:22:19.646] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:22:21.539] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:22:23.589] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:22:25.328] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:22:27.480] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:22:29.328] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:22:31.375] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:22:33.217] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:22:35.063] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:22:36.901] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:22:38.748] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:22:40.588] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 17:22:42.432] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:22:44.191] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:22:46.733] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:22:48.575] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:22:50.419] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:22:52.466] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:22:54.236] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:22:55.947] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:22:57.716] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:22:59.637] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:23:01.478] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:23:03.523] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:23:05.372] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:23:07.213] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:23:09.054] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:23:10.895] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:23:12.950] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:23:14.788] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:23:16.835] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:23:18.571] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:23:20.369] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:23:22.165] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:23:24.095] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:23:26.057] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:23:27.897] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:23:29.594] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:23:31.382] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:23:33.225] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:23:35.064] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:23:36.905] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:23:38.752] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:23:40.453] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:23:42.236] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:23:44.081] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:23:46.125] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:23:47.967] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:23:49.911] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:23:51.653] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:23:53.500] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:23:55.543] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:23:57.184] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:23:59.167] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:24:00.870] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:24:02.717] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:24:04.555] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:24:06.400] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:24:08.351] [INFO] [api:fetch:236] Fetched 93 tweets\n",
      "[2023-04-22 17:24:10.395] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 17:24:12.241] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:24:14.079] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:24:15.923] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:24:17.765] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:24:19.770] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:24:21.452] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:24:23.295] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:24:25.139] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:24:26.983] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:24:28.823] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:24:30.667] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:24:32.742] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:24:34.970] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 17:24:36.812] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 17:24:38.657] [INFO] [api:fetch:236] Fetched 96 tweets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-22 17:24:40.364] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 17:24:42.346] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:24:44.390] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:24:46.233] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:24:48.082] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:24:49.919] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:24:51.764] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:24:53.606] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:24:56.063] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:24:57.902] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 17:24:59.750] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:25:01.611] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:25:03.437] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 17:25:05.279] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:25:07.122] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:25:09.174] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:25:10.808] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 17:25:12.654] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:25:14.694] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 17:25:16.337] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 17:25:18.180] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:25:20.024] [INFO] [api:fetch:236] Fetched 88 tweets\n",
      "[2023-04-22 17:25:21.725] [INFO] [api:fetch:236] Fetched 94 tweets\n",
      "[2023-04-22 17:25:23.710] [INFO] [api:fetch:236] Fetched 93 tweets\n",
      "[2023-04-22 17:25:25.554] [INFO] [api:fetch:236] Fetched 94 tweets\n",
      "[2023-04-22 17:25:27.399] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 17:25:29.248] [INFO] [api:fetch:236] Fetched 93 tweets\n",
      "[2023-04-22 17:25:31.063] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:25:32.927] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:25:34.701] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:25:36.612] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:25:38.253] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:25:40.100] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:25:42.038] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 17:25:43.746] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:25:45.779] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:25:47.675] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:25:49.531] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:25:51.361] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:25:53.002] [INFO] [api:fetch:236] Fetched 94 tweets\n",
      "[2023-04-22 17:25:55.460] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:25:57.919] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:25:59.659] [INFO] [api:fetch:236] Fetched 93 tweets\n",
      "[2023-04-22 17:26:01.504] [INFO] [api:fetch:236] Fetched 91 tweets\n",
      "[2023-04-22 17:26:03.295] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 17:26:05.183] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:26:06.790] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:26:08.633] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:26:10.507] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:26:12.146] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:26:13.852] [INFO] [api:fetch:236] Fetched 89 tweets\n",
      "[2023-04-22 17:26:15.626] [INFO] [api:fetch:236] Fetched 86 tweets\n",
      "[2023-04-22 17:26:17.473] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 17:26:19.315] [INFO] [api:fetch:236] Fetched 93 tweets\n",
      "[2023-04-22 17:26:21.159] [INFO] [api:fetch:236] Fetched 94 tweets\n",
      "[2023-04-22 17:26:22.898] [INFO] [api:fetch:236] Fetched 94 tweets\n",
      "[2023-04-22 17:26:24.660] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:26:26.483] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:26:28.323] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:26:30.072] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:26:31.912] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:26:33.758] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:26:35.599] [INFO] [api:fetch:236] Fetched 97 tweets\n"
     ]
    }
   ],
   "source": [
    "target_total = 30000\n",
    "keyword = 'gpt'\n",
    "start_date = '2023-03-15'   \n",
    "end_date = '2023-03-17'\n",
    "retweets = False\n",
    "after_4_1 = History.fetch(keyword=keyword, start_date= start_date, end_date= end_date, \n",
    "                    target_total=target_total, retweets=retweets) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4f4b6c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df20230316 = after_4_1[after_4_1.created_at>'2023-03-16']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ed811a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-22 17:28:19.230] [INFO] [api:fetch:236] Fetched 94 tweets\n",
      "[2023-04-22 17:28:20.882] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:28:22.513] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:28:24.143] [INFO] [api:fetch:236] Fetched 93 tweets\n",
      "[2023-04-22 17:28:25.784] [INFO] [api:fetch:236] Fetched 91 tweets\n",
      "[2023-04-22 17:28:27.437] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 17:28:28.934] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:28:30.492] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:28:32.097] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 17:28:33.768] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:28:35.410] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:28:37.251] [INFO] [api:fetch:236] Fetched 88 tweets\n",
      "[2023-04-22 17:28:38.784] [INFO] [api:fetch:236] Fetched 87 tweets\n",
      "[2023-04-22 17:28:40.389] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 17:28:42.097] [INFO] [api:fetch:236] Fetched 93 tweets\n",
      "[2023-04-22 17:28:43.662] [INFO] [api:fetch:236] Fetched 94 tweets\n",
      "[2023-04-22 17:28:45.218] [INFO] [api:fetch:236] Fetched 94 tweets\n",
      "[2023-04-22 17:28:46.723] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:28:48.312] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:28:49.806] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:28:51.381] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:28:52.943] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:28:54.520] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:28:56.298] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:28:57.954] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 17:28:59.790] [INFO] [api:fetch:236] Fetched 94 tweets\n",
      "[2023-04-22 17:29:01.555] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:29:03.189] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:29:04.821] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:29:06.476] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:29:08.310] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:29:10.003] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:29:11.719] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:29:13.543] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:29:15.343] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:29:17.187] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:29:19.027] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:29:20.871] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:29:22.513] [INFO] [api:fetch:236] Fetched 92 tweets\n",
      "[2023-04-22 17:29:24.225] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:29:26.207] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:29:28.047] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:29:30.089] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:29:31.866] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:29:33.779] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:29:35.618] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:29:37.464] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:29:39.305] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:29:41.151] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:29:43.097] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:29:45.529] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:29:47.172] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:29:49.005] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:29:50.818] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:29:52.568] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 17:29:54.281] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:29:56.104] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:29:57.786] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:29:59.802] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:30:01.455] [INFO] [api:fetch:236] Fetched 94 tweets\n",
      "[2023-04-22 17:30:03.271] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:30:05.104] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 17:30:06.951] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 17:30:08.807] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:30:10.641] [INFO] [api:fetch:236] Fetched 90 tweets\n",
      "[2023-04-22 17:30:12.483] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 17:30:14.531] [INFO] [api:fetch:236] Fetched 94 tweets\n",
      "[2023-04-22 17:30:16.275] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:30:18.016] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 17:30:19.857] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 17:30:21.700] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:30:23.751] [INFO] [api:fetch:236] Fetched 93 tweets\n",
      "[2023-04-22 17:30:25.591] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 17:30:27.294] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 17:30:28.472] [INFO] [api:fetch:227] Sleeping\n",
      "[2023-04-22 17:45:30.192] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 17:45:32.037] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:45:33.874] [INFO] [api:fetch:236] Fetched 94 tweets\n",
      "[2023-04-22 17:45:35.717] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 17:45:37.564] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 17:45:39.409] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:45:41.198] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:45:43.084] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:45:44.933] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:45:46.780] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:45:48.621] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:45:50.462] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:45:52.310] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:45:54.160] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:45:56.604] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:45:58.456] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:46:00.296] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:46:02.140] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:46:03.980] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:46:05.827] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:46:07.673] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:46:09.514] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:46:11.357] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:46:13.203] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:46:15.036] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:46:16.886] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:46:18.725] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:46:20.778] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:46:22.618] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:46:24.457] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:46:26.306] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:46:28.142] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:46:29.986] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:46:31.830] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:46:34.293] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:46:36.743] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 17:46:38.594] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:46:40.435] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 17:46:42.284] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:46:44.134] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 17:46:45.964] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:46:47.812] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:46:49.501] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:46:51.293] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:46:53.137] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:46:54.982] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:46:56.820] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:46:58.529] [INFO] [api:fetch:236] Fetched 99 tweets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-22 17:47:00.303] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:47:02.143] [INFO] [api:fetch:236] Fetched 93 tweets\n",
      "[2023-04-22 17:47:03.990] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 17:47:05.839] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:47:07.677] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:47:09.314] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:47:10.950] [INFO] [api:fetch:236] Fetched 93 tweets\n",
      "[2023-04-22 17:47:12.797] [INFO] [api:fetch:236] Fetched 89 tweets\n",
      "[2023-04-22 17:47:14.643] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:47:16.492] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:47:18.205] [INFO] [api:fetch:236] Fetched 94 tweets\n",
      "[2023-04-22 17:47:19.966] [INFO] [api:fetch:236] Fetched 93 tweets\n",
      "[2023-04-22 17:47:22.013] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 17:47:23.723] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 17:47:25.494] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:47:27.335] [INFO] [api:fetch:236] Fetched 93 tweets\n",
      "[2023-04-22 17:47:29.180] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:47:31.023] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:47:33.074] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 17:47:35.120] [INFO] [api:fetch:236] Fetched 94 tweets\n",
      "[2023-04-22 17:47:36.961] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:47:38.807] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:47:40.649] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:47:42.384] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:47:44.132] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:47:45.992] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:47:47.818] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:47:49.835] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:47:51.912] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 17:47:53.604] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:47:55.396] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:47:57.238] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 17:47:59.078] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:48:00.919] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:48:02.767] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:48:04.628] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:48:06.455] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 17:48:08.496] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:48:10.549] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:48:12.391] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:48:14.243] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:48:16.288] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:48:18.332] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:48:20.171] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:48:22.017] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:48:23.860] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:48:25.906] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:48:27.749] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:48:29.615] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:48:31.404] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:48:33.280] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:48:35.130] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:48:36.964] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:48:38.817] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 17:48:40.660] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:48:42.498] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:48:44.438] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:48:46.176] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:48:48.031] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 17:48:49.871] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:48:51.715] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:48:53.354] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:48:55.198] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:48:57.041] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:48:58.879] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:49:00.728] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:49:02.567] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:49:04.415] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 17:49:06.257] [INFO] [api:fetch:236] Fetched 94 tweets\n",
      "[2023-04-22 17:49:08.106] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 17:49:09.738] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 17:49:11.587] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:49:13.430] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:49:15.275] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 17:49:16.960] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:49:19.164] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:49:21.000] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:49:22.841] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:49:24.689] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:49:26.532] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:49:28.402] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:49:30.216] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:49:31.924] [INFO] [api:fetch:236] Fetched 92 tweets\n",
      "[2023-04-22 17:49:33.702] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:49:35.541] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:49:37.217] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:49:39.226] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:49:41.079] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:49:43.121] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:49:44.971] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 17:49:46.712] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:49:48.446] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:49:50.289] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:49:52.135] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 17:49:53.977] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:49:55.818] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:49:57.665] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 17:49:59.507] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:50:01.349] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:50:03.191] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:50:05.041] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:50:06.877] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 17:50:08.722] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:50:10.565] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:50:12.409] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:50:14.250] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:50:16.096] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:50:18.144] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:50:20.193] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:50:22.032] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:50:23.873] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:50:26.336] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:50:28.180] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:50:30.022] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:50:31.767] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:50:33.502] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:50:35.346] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:50:37.189] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:50:39.645] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:50:41.491] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:50:43.335] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:50:45.181] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:50:47.222] [INFO] [api:fetch:236] Fetched 100 tweets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-22 17:50:49.068] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:50:50.909] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:50:52.753] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:50:54.800] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:50:56.646] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:50:58.492] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:51:00.546] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:51:02.584] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:51:05.246] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:51:07.091] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:51:08.934] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:51:10.777] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:51:12.619] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:51:14.463] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:51:16.310] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:51:18.157] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:51:20.608] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:51:22.454] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:51:24.292] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:51:26.137] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:51:27.982] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:51:29.819] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:51:31.665] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:51:33.516] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:51:35.555] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:51:37.403] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:51:39.244] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:51:40.883] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 17:51:42.931] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:51:44.976] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:51:46.817] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 17:51:48.664] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:51:50.506] [INFO] [api:fetch:236] Fetched 94 tweets\n",
      "[2023-04-22 17:51:52.352] [INFO] [api:fetch:236] Fetched 93 tweets\n",
      "[2023-04-22 17:51:54.197] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:51:56.042] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:51:57.879] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:51:59.724] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:52:01.564] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 17:52:03.411] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:52:05.250] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:52:07.100] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:52:08.941] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:52:10.783] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 17:52:12.833] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:52:14.470] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:52:16.313] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:52:18.155] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 17:52:20.003] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:52:21.841] [INFO] [api:fetch:236] Fetched 93 tweets\n",
      "[2023-04-22 17:52:23.684] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:52:25.530] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:52:27.986] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:52:29.833] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:52:31.480] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 17:52:33.314] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:52:35.156] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 17:52:36.997] [INFO] [api:fetch:236] Fetched 94 tweets\n",
      "[2023-04-22 17:52:38.844] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 17:52:40.687] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:52:42.528] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:52:44.370] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 17:52:46.194] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:52:48.257] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:52:50.104] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:52:51.949] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-22 17:52:53.795] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:52:55.429] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:52:57.273] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:52:59.115] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:53:00.962] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:53:03.006] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:53:04.843] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:53:06.690] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:53:08.336] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:53:10.061] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-22 17:53:12.022] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:53:13.855] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:53:15.499] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:53:17.347] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:53:19.189] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:53:20.824] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:53:22.671] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:53:24.919] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:53:26.767] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:53:28.607] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:53:30.410] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:53:32.291] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:53:33.933] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:53:35.569] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:53:37.413] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-22 17:53:39.259] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:53:41.103] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:53:43.147] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-22 17:53:44.985] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-22 17:53:46.834] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-22 17:53:48.431] [INFO] [api:fetch:236] Fetched 13 tweets\n"
     ]
    }
   ],
   "source": [
    "target_total = 50000\n",
    "keyword = 'gpt'\n",
    "start_date = '2023-03-15'   \n",
    "end_date = '2023-03-16'\n",
    "retweets = False\n",
    "after_4_2 = History.fetch(keyword=keyword, start_date= start_date, end_date= end_date, \n",
    "                    target_total=target_total, retweets=retweets) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "22b4daa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4 = pd.concat([df20230317, df20230316, after_4_2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6b8cc1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-22 17:55:09.485] [INFO] [api:write:61] Writing 85200 rows to table after_4\n"
     ]
    }
   ],
   "source": [
    "# write file\n",
    "fname_db = f\"data/esther\"  \n",
    "DB.write(table_name='after_4', path=fname_db, data=df_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7edb90ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>geo</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-17T23:59:55.000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>✅ #PUMP $RNDR! +0.711% in 15 seconds\\nCurrent price: 1.5729$!\\n\\nFollow and 💛 for more signals!\\n59 #ai #GPT #BUSD #crypto #btcusdt #alts #finance #binance #RNDR https://t.co/EJO4xoy7g2</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1636880073105231872</td>\n",
       "      <td>1539171807755919361</td>\n",
       "      <td>1636880073105231872</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>{'annotations': [{'start': 9, 'end': 12, 'probability': 0.4008, 'type': 'Other', 'normalized_text': 'RNDR'}, {'start': 101, 'end': 103, 'probability': 0.3828, 'type': 'Other', 'normalized_text': 'GPT'}, {'start': 106, 'end': 109, 'probability': 0.4246, 'type': 'Other', 'normalized_text': 'BUSD'}, {'start': 112, 'end': 117, 'probability': 0.4985, 'type': 'Other', 'normalized_text': 'crypto'}, {'start': 120, 'end': 126, 'probability': 0.6118, 'type': 'Other', 'normalized_text': 'btcusdt'}, {'start': 153, 'end': 156, 'probability': 0.407, 'type': 'Other', 'normalized_text': 'RNDR'}], 'hashtags': [{'start': 2, 'end': 7, 'tag': 'PUMP'}, {'start': 96, 'end': 99, 'tag': 'ai'}, {'start': 100, 'end': 104, 'tag': 'GPT'}, {'start': 105, 'end': 110, 'tag': 'BUSD'}, {'start': 111, 'end': 118, 'tag': 'crypto'}, {'start': 119, 'end': 127, 'tag': 'btcusdt'}, {'start': 128, 'end': 133, 'tag': 'alts'}, {'start': 134, 'end': 142, 'tag': 'finance'}, {'start': 143, 'end': 151, 'tag': 'binance'}, {'start': 152, 'end': 157, 'tag': 'RNDR'}], 'urls': [{'start': 158, 'end': 181, 'url': 'https://t.co/EJO4xoy7g2', 'expanded_url': 'https://twitter.com/TraderJetBot/status/1636880073105231872/photo/1', 'display_url': 'pic.twitter.com/EJO4xoy7g2', 'media_key': '3_1636880072140541952'}], 'cashtags': [{'start': 8, 'end': 13, 'tag': 'RNDR'}]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-17T23:59:53.000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>OpenAI’s GPT Is Helping Turn Text Into Custom Metaverse Worlds - Decrypt https://t.co/AsZjAzle9i</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1636880062384570369</td>\n",
       "      <td>1266779097088303106</td>\n",
       "      <td>1636880062384570369</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>{'annotations': [{'start': 0, 'end': 5, 'probability': 0.8148, 'type': 'Organization', 'normalized_text': 'OpenAI'}, {'start': 9, 'end': 11, 'probability': 0.3777, 'type': 'Other', 'normalized_text': 'GPT'}], 'urls': [{'start': 73, 'end': 96, 'url': 'https://t.co/AsZjAzle9i', 'expanded_url': 'https://decrypt.co/123906/openai-gpt-text-custom-metaverse-worlds', 'display_url': 'decrypt.co/123906/openai-…', 'images': [{'url': 'https://pbs.twimg.com/news_img/1640036655863066625/TMBHV8aN?format=jpg&amp;name=orig', 'width': 1024, 'height': 512}, {'url': 'https://pbs.twimg.com/news_img/1640036655863066625/TMBHV8aN?format=jpg&amp;name=150x150', 'width': 150, 'height': 150}], 'status': 200, 'title': 'OpenAI’s GPT Is Helping Turn Text Into Custom Metaverse Worlds - Decrypt', 'description': 'Web3 metaverse platform Oncyber is adding an AI tool that lets users change up 3D spaces by typing out ideas.', 'unwound_url': 'https://decrypt.co/123906/openai-gpt-text-custom-metaverse-worlds'}]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-17T23:59:52.000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>ChatGTP (GPT-4) will be used to write fake product reviews online</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1636880060937371649</td>\n",
       "      <td>78114227</td>\n",
       "      <td>1636880060937371649</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>{'annotations': [{'start': 0, 'end': 6, 'probability': 0.8909, 'type': 'Other', 'normalized_text': 'ChatGTP'}, {'start': 9, 'end': 13, 'probability': 0.7721, 'type': 'Other', 'normalized_text': 'GPT-4'}]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-17T23:59:43.000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>@EDUreboot @michalkosinski You only need one person in the world with decent GPU hardware to kickstart a gpt and prompt it to go viral. Maybe gpt-4, maybe 5, but either way it's straightforward and will happen soon</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1636880022911713281</td>\n",
       "      <td>296557381</td>\n",
       "      <td>1636683810631974912</td>\n",
       "      <td>779536468708425729</td>\n",
       "      <td>nan</td>\n",
       "      <td>{'annotations': [{'start': 77, 'end': 79, 'probability': 0.5177, 'type': 'Other', 'normalized_text': 'GPU'}], 'mentions': [{'start': 0, 'end': 10, 'username': 'EDUreboot', 'id': '779536468708425729'}, {'start': 11, 'end': 26, 'username': 'michalkosinski', 'id': '52401341'}]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-17T23:59:41.000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>✅ #PUMP $RNDR! +1.114% in 15 seconds\\nCurrent price: 1.5618$!\\n\\nFollow and ❤️ for more signals!\\n29 #ai #GPT #USDC #cryptocommunity #btcusdt #altcoins #finance #binance #RNDR https://t.co/hKojs3Yvfi</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1636880010899496965</td>\n",
       "      <td>1539171807755919361</td>\n",
       "      <td>1636880010899496965</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>{'annotations': [{'start': 9, 'end': 12, 'probability': 0.4664, 'type': 'Other', 'normalized_text': 'RNDR'}, {'start': 102, 'end': 104, 'probability': 0.5316, 'type': 'Other', 'normalized_text': 'GPT'}, {'start': 107, 'end': 110, 'probability': 0.6255, 'type': 'Other', 'normalized_text': 'USDC'}, {'start': 113, 'end': 127, 'probability': 0.4939, 'type': 'Other', 'normalized_text': 'cryptocommunity'}, {'start': 130, 'end': 136, 'probability': 0.6913, 'type': 'Other', 'normalized_text': 'btcusdt'}, {'start': 167, 'end': 170, 'probability': 0.5509, 'type': 'Other', 'normalized_text': 'RNDR'}], 'hashtags': [{'start': 2, 'end': 7, 'tag': 'PUMP'}, {'start': 97, 'end': 100, 'tag': 'ai'}, {'start': 101, 'end': 105, 'tag': 'GPT'}, {'start': 106, 'end': 111, 'tag': 'USDC'}, {'start': 112, 'end': 128, 'tag': 'cryptocommunity'}, {'start': 129, 'end': 137, 'tag': 'btcusdt'}, {'start': 138, 'end': 147, 'tag': 'altcoins'}, {'start': 148, 'end': 156, 'tag': 'finance'}, {'start': 157, 'end': 165, 'tag': 'binance'}, {'start': 166, 'end': 171, 'tag': 'RNDR'}], 'urls': [{'start': 172, 'end': 195, 'url': 'https://t.co/hKojs3Yvfi', 'expanded_url': 'https://twitter.com/TraderJetBot/status/1636880010899496965/photo/1', 'display_url': 'pic.twitter.com/hKojs3Yvfi', 'media_key': '3_1636880009897086977'}], 'cashtags': [{'start': 8, 'end': 13, 'tag': 'RNDR'}]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85195</th>\n",
       "      <td>2023-03-15T00:00:07.000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>GPT-4\\n→ https://t.co/DPpe0zc41v\\n\\nKali Linux 2023.1 introduces &amp;amp;amp;#x27;Purple&amp;amp;amp;#x27; distro for defensive security\\n→ https://t.co/6eeh9j7xye\\n\\nGPT-4 is phenomenal at Code\\n→ https://t.co/46QTix3v7q</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1635792957574979584</td>\n",
       "      <td>800363709528883200</td>\n",
       "      <td>1635792957574979584</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>{'hashtags': [{'start': 71, 'end': 75, 'tag': 'x27'}, {'start': 91, 'end': 95, 'tag': 'x27'}], 'urls': [{'start': 8, 'end': 31, 'url': 'https://t.co/DPpe0zc41v', 'expanded_url': 'https://openai.com/research/gpt-4', 'display_url': 'openai.com/research/gpt-4', 'images': [{'url': 'https://pbs.twimg.com/news_img/1648709685430861825/HD4XdKTK?format=jpg&amp;name=orig', 'width': 2048, 'height': 1367}, {'url': 'https://pbs.twimg.com/news_img/1648709685430861825/HD4XdKTK?format=jpg&amp;name=150x150', 'width': 150, 'height': 150}], 'status': 200, 'title': 'GPT-4', 'description': 'We’ve created GPT-4, the latest milestone in OpenAI’s effort in scaling up deep learning. GPT-4 is a large multimodal model (accepting image and text inputs, emitting text outputs) that, while less capable than humans in many real-world scenarios, exhibits human-level performance on various professional and academic benchmarks.', 'unwound_url': 'https://openai.com/research/gpt-4'}, {'start': 129, 'end': 152, 'url': 'https://t.co/6eeh9j7xye', 'expanded_url': 'https://gitlab.com/kalilinux/kali-purple/documentation/-/wikis/home', 'display_url': 'gitlab.com/kalilinux/kali…', 'images': [{'url': 'https://pbs.twimg.com/news_img/1645910119450828802/Bh4sx5u8?format=png&amp;name=orig', 'width': 246, 'height': 200}, {'url': 'https://pbs.twimg.com/news_img/1645910119450828802/Bh4sx5u8?format=png&amp;name=150x150', 'width': 150, 'height': 150}], 'status': 200, 'title': 'Home · Wiki · Kali Linux / kali-purple / Documentation · GitLab', 'description': 'The ultimate SOC-in-a-box community project', 'unwound_url': 'https://gitlab.com/kalilinux/kali-purple/documentation/-/wikis/home'}, {'start': 184, 'end': 207, 'url': 'https://t.co/46QTix3v7q', 'expanded_url': 'https://github.com/anysphere/gpt-4-for-code', 'display_url': 'github.com/anysphere/gpt-…', 'images': [{'url': 'https://pbs.twimg.com/news_img/1644410478784032768/MX7wyH9A?format=jpg&amp;name=orig', 'width': 1200, 'height': 600}, {'url': 'https://pbs.twimg.com/news_img/1644410478784032768/MX7wyH9A?format=jpg&amp;name=150x150', 'width': 150, 'height': 150}], 'status': 200, 'title': 'GitHub - anysphere/gpt-4-for-code: Some examples of GPT-4 for code!', 'description': 'Some examples of GPT-4 for code! Contribute to anysphere/gpt-4-for-code development by creating an account on GitHub.', 'unwound_url': 'https://github.com/anysphere/gpt-4-for-code'}], 'annotations': [{'start': 0, 'end': 4, 'probability': 0.6125, 'type': 'Other', 'normalized_text': 'GPT-4'}, {'start': 33, 'end': 42, 'probability': 0.7377, 'type': 'Other', 'normalized_text': 'Kali Linux'}, {'start': 48, 'end': 48, 'probability': 0.5643, 'type': 'Other', 'normalized_text': '.'}, {'start': 154, 'end': 156, 'probability': 0.4807, 'type': 'Other', 'normalized_text': 'GPT'}]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85196</th>\n",
       "      <td>2023-03-15T00:00:03.000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>@jordanbpeterson GPT-4 seems to have significantly addressed the bias problem.</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1635792941271613440</td>\n",
       "      <td>2721724674</td>\n",
       "      <td>1635552386256101379</td>\n",
       "      <td>95092020</td>\n",
       "      <td>nan</td>\n",
       "      <td>{'mentions': [{'start': 0, 'end': 16, 'username': 'jordanbpeterson', 'id': '95092020'}], 'annotations': [{'start': 17, 'end': 21, 'probability': 0.896, 'type': 'Other', 'normalized_text': 'GPT-4'}]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85197</th>\n",
       "      <td>2023-03-15T00:00:01.000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>GPT-4 is out, and the results are astounding: better than most students, can reason in several languages!\\n\\n#ChatGPT was just the beginning. AI #altcoins will rule the bullrun!\\n$ICP \\n$TAO \\n$FET \\n$AGIX \\n$DAG \\n$VXV\\n$OCEAN\\n$NMR\\n$GRT\\n$HERA\\n$DKA\\n$CTXC\\n$DBC\\n$___👇</td>\n",
       "      <td>en</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1635792932757446657</td>\n",
       "      <td>913374738071932933</td>\n",
       "      <td>1635792932757446657</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>{'hashtags': [{'start': 107, 'end': 115, 'tag': 'ChatGPT'}, {'start': 143, 'end': 152, 'tag': 'altcoins'}], 'annotations': [{'start': 0, 'end': 4, 'probability': 0.7424, 'type': 'Other', 'normalized_text': 'GPT-4'}, {'start': 108, 'end': 114, 'probability': 0.6574, 'type': 'Other', 'normalized_text': 'ChatGPT'}, {'start': 144, 'end': 151, 'probability': 0.5616, 'type': 'Other', 'normalized_text': 'altcoins'}, {'start': 177, 'end': 179, 'probability': 0.4255, 'type': 'Other', 'normalized_text': 'ICP'}, {'start': 183, 'end': 185, 'probability': 0.4456, 'type': 'Other', 'normalized_text': 'TAO'}, {'start': 189, 'end': 191, 'probability': 0.461, 'type': 'Other', 'normalized_text': 'FET'}, {'start': 195, 'end': 198, 'probability': 0.5441, 'type': 'Other', 'normalized_text': 'AGIX'}, {'start': 202, 'end': 204, 'probability': 0.5917, 'type': 'Other', 'normalized_text': 'DAG'}, {'start': 208, 'end': 210, 'probability': 0.5943, 'type': 'Other', 'normalized_text': 'VXV'}, {'start': 213, 'end': 217, 'probability': 0.5958, 'type': 'Other', 'normalized_text': 'OCEAN'}, {'start': 220, 'end': 222, 'probability': 0.4641, 'type': 'Other', 'normalized_text': 'NMR'}, {'start': 225, 'end': 227, 'probability': 0.5135, 'type': 'Other', 'normalized_text': 'GRT'}, {'start': 230, 'end': 233, 'probability': 0.5169, 'type': 'Other', 'normalized_text': 'HERA'}, {'start': 236, 'end': 238, 'probability': 0.4251, 'type': 'Other', 'normalized_text': 'DKA'}, {'start': 241, 'end': 244, 'probability': 0.478, 'type': 'Other', 'normalized_text': 'CTXC'}, {'start': 247, 'end': 249, 'probability': 0.3636, 'type': 'Other', 'normalized_text': 'DBC'}], 'cashtags': [{'start': 176, 'end': 180, 'tag': 'ICP'}, {'start': 182, 'end': 186, 'tag': 'TAO'}, {'start': 188, 'end': 192, 'tag': 'FET'}, {'start': 194, 'end': 199, 'tag': 'AGIX'}, {'start': 201, 'end': 205, 'tag': 'DAG'}, {'start': 207, 'end': 211, 'tag': 'VXV'}, {'start': 212, 'end': 218, 'tag': 'OCEAN'}, {'start': 219, 'end': 223, 'tag': 'NMR'}, {'start': 224, 'end': 228, 'tag': 'GRT'}, {'start': 229, 'end': 234, 'tag': 'HERA'}, {'start': 235, 'end': 239, 'tag': 'DKA'}, {'start': 240, 'end': 245, 'tag': 'CTXC'}, {'start': 246, 'end': 250, 'tag': 'DBC'}]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85198</th>\n",
       "      <td>2023-03-15T00:00:00.000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>Be My Eyes (now using GPT-4) https://t.co/ZkEIkfcMAd</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1635792928135102467</td>\n",
       "      <td>12467182</td>\n",
       "      <td>1635792928135102467</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>{'urls': [{'start': 29, 'end': 52, 'url': 'https://t.co/ZkEIkfcMAd', 'expanded_url': 'https://openai.com/customer-stories/be-my-eyes', 'display_url': 'openai.com/customer-stori…', 'images': [{'url': 'https://pbs.twimg.com/news_img/1646723707015168003/TgIkIOoZ?format=jpg&amp;name=orig', 'width': 1290, 'height': 1290}, {'url': 'https://pbs.twimg.com/news_img/1646723707015168003/TgIkIOoZ?format=jpg&amp;name=150x150', 'width': 150, 'height': 150}], 'status': 200, 'title': 'Be My Eyes', 'description': 'Be My Eyes uses GPT-4 to transform visual accessibility.', 'unwound_url': 'https://openai.com/customer-stories/be-my-eyes'}], 'annotations': [{'start': 0, 'end': 9, 'probability': 0.9768, 'type': 'Other', 'normalized_text': 'Be My Eyes'}, {'start': 22, 'end': 26, 'probability': 0.9014, 'type': 'Other', 'normalized_text': 'GPT-4'}]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85199</th>\n",
       "      <td>2023-03-15T00:00:00.000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>GPT-4 doesn’t really know it exists yet https://t.co/TOStSF7FP8</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1635792927963095040</td>\n",
       "      <td>710444513706307584</td>\n",
       "      <td>1635792927963095040</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>{'urls': [{'start': 40, 'end': 63, 'url': 'https://t.co/TOStSF7FP8', 'expanded_url': 'https://twitter.com/xdmbna/status/1635792927963095040/photo/1', 'display_url': 'pic.twitter.com/TOStSF7FP8', 'media_key': '3_1635792924225961985'}], 'annotations': [{'start': 0, 'end': 4, 'probability': 0.9456, 'type': 'Other', 'normalized_text': 'GPT-4'}]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85200 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     created_at screen_name  \\\n",
       "0      2023-03-17T23:59:55.000Z        None   \n",
       "1      2023-03-17T23:59:53.000Z        None   \n",
       "2      2023-03-17T23:59:52.000Z        None   \n",
       "3      2023-03-17T23:59:43.000Z        None   \n",
       "4      2023-03-17T23:59:41.000Z        None   \n",
       "...                         ...         ...   \n",
       "85195  2023-03-15T00:00:07.000Z        None   \n",
       "85196  2023-03-15T00:00:03.000Z        None   \n",
       "85197  2023-03-15T00:00:01.000Z        None   \n",
       "85198  2023-03-15T00:00:00.000Z        None   \n",
       "85199  2023-03-15T00:00:00.000Z        None   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                   text  \\\n",
       "0                                                                                             ✅ #PUMP $RNDR! +0.711% in 15 seconds\\nCurrent price: 1.5729$!\\n\\nFollow and 💛 for more signals!\\n59 #ai #GPT #BUSD #crypto #btcusdt #alts #finance #binance #RNDR https://t.co/EJO4xoy7g2   \n",
       "1                                                                                                                                                                                      OpenAI’s GPT Is Helping Turn Text Into Custom Metaverse Worlds - Decrypt https://t.co/AsZjAzle9i   \n",
       "2                                                                                                                                                                                                                     ChatGTP (GPT-4) will be used to write fake product reviews online   \n",
       "3                                                                @EDUreboot @michalkosinski You only need one person in the world with decent GPU hardware to kickstart a gpt and prompt it to go viral. Maybe gpt-4, maybe 5, but either way it's straightforward and will happen soon   \n",
       "4                                                                               ✅ #PUMP $RNDR! +1.114% in 15 seconds\\nCurrent price: 1.5618$!\\n\\nFollow and ❤️ for more signals!\\n29 #ai #GPT #USDC #cryptocommunity #btcusdt #altcoins #finance #binance #RNDR https://t.co/hKojs3Yvfi   \n",
       "...                                                                                                                                                                                                                                                                                 ...   \n",
       "85195                                                            GPT-4\\n→ https://t.co/DPpe0zc41v\\n\\nKali Linux 2023.1 introduces &amp;amp;#x27;Purple&amp;amp;#x27; distro for defensive security\\n→ https://t.co/6eeh9j7xye\\n\\nGPT-4 is phenomenal at Code\\n→ https://t.co/46QTix3v7q   \n",
       "85196                                                                                                                                                                                                    @jordanbpeterson GPT-4 seems to have significantly addressed the bias problem.   \n",
       "85197  GPT-4 is out, and the results are astounding: better than most students, can reason in several languages!\\n\\n#ChatGPT was just the beginning. AI #altcoins will rule the bullrun!\\n$ICP \\n$TAO \\n$FET \\n$AGIX \\n$DAG \\n$VXV\\n$OCEAN\\n$NMR\\n$GRT\\n$HERA\\n$DKA\\n$CTXC\\n$DBC\\n$___👇   \n",
       "85198                                                                                                                                                                                                                              Be My Eyes (now using GPT-4) https://t.co/ZkEIkfcMAd   \n",
       "85199                                                                                                                                                                                                                   GPT-4 doesn’t really know it exists yet https://t.co/TOStSF7FP8   \n",
       "\n",
       "      lang  retweet_count  reply_count  like_count  quote_count  \\\n",
       "0       en              0            0           1            0   \n",
       "1       en              0            0           0            0   \n",
       "2       en              0            0           0            0   \n",
       "3       en              0            0           0            0   \n",
       "4       en              0            0           1            0   \n",
       "...    ...            ...          ...         ...          ...   \n",
       "85195   en              0            0           0            0   \n",
       "85196   en              0            0           0            0   \n",
       "85197   en              2            8          28            0   \n",
       "85198   en              0            0           0            0   \n",
       "85199   en              0            0           0            0   \n",
       "\n",
       "                        id            author_id      conversation_id  \\\n",
       "0      1636880073105231872  1539171807755919361  1636880073105231872   \n",
       "1      1636880062384570369  1266779097088303106  1636880062384570369   \n",
       "2      1636880060937371649             78114227  1636880060937371649   \n",
       "3      1636880022911713281            296557381  1636683810631974912   \n",
       "4      1636880010899496965  1539171807755919361  1636880010899496965   \n",
       "...                    ...                  ...                  ...   \n",
       "85195  1635792957574979584   800363709528883200  1635792957574979584   \n",
       "85196  1635792941271613440           2721724674  1635552386256101379   \n",
       "85197  1635792932757446657   913374738071932933  1635792932757446657   \n",
       "85198  1635792928135102467             12467182  1635792928135102467   \n",
       "85199  1635792927963095040   710444513706307584  1635792927963095040   \n",
       "\n",
       "      in_reply_to_user_id  geo  \\\n",
       "0                     nan  nan   \n",
       "1                     nan  nan   \n",
       "2                     nan  nan   \n",
       "3      779536468708425729  nan   \n",
       "4                     nan  nan   \n",
       "...                   ...  ...   \n",
       "85195                 nan  nan   \n",
       "85196            95092020  nan   \n",
       "85197                 nan  nan   \n",
       "85198                 nan  nan   \n",
       "85199                 nan  nan   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        entities  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              {'annotations': [{'start': 9, 'end': 12, 'probability': 0.4008, 'type': 'Other', 'normalized_text': 'RNDR'}, {'start': 101, 'end': 103, 'probability': 0.3828, 'type': 'Other', 'normalized_text': 'GPT'}, {'start': 106, 'end': 109, 'probability': 0.4246, 'type': 'Other', 'normalized_text': 'BUSD'}, {'start': 112, 'end': 117, 'probability': 0.4985, 'type': 'Other', 'normalized_text': 'crypto'}, {'start': 120, 'end': 126, 'probability': 0.6118, 'type': 'Other', 'normalized_text': 'btcusdt'}, {'start': 153, 'end': 156, 'probability': 0.407, 'type': 'Other', 'normalized_text': 'RNDR'}], 'hashtags': [{'start': 2, 'end': 7, 'tag': 'PUMP'}, {'start': 96, 'end': 99, 'tag': 'ai'}, {'start': 100, 'end': 104, 'tag': 'GPT'}, {'start': 105, 'end': 110, 'tag': 'BUSD'}, {'start': 111, 'end': 118, 'tag': 'crypto'}, {'start': 119, 'end': 127, 'tag': 'btcusdt'}, {'start': 128, 'end': 133, 'tag': 'alts'}, {'start': 134, 'end': 142, 'tag': 'finance'}, {'start': 143, 'end': 151, 'tag': 'binance'}, {'start': 152, 'end': 157, 'tag': 'RNDR'}], 'urls': [{'start': 158, 'end': 181, 'url': 'https://t.co/EJO4xoy7g2', 'expanded_url': 'https://twitter.com/TraderJetBot/status/1636880073105231872/photo/1', 'display_url': 'pic.twitter.com/EJO4xoy7g2', 'media_key': '3_1636880072140541952'}], 'cashtags': [{'start': 8, 'end': 13, 'tag': 'RNDR'}]}  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           {'annotations': [{'start': 0, 'end': 5, 'probability': 0.8148, 'type': 'Organization', 'normalized_text': 'OpenAI'}, {'start': 9, 'end': 11, 'probability': 0.3777, 'type': 'Other', 'normalized_text': 'GPT'}], 'urls': [{'start': 73, 'end': 96, 'url': 'https://t.co/AsZjAzle9i', 'expanded_url': 'https://decrypt.co/123906/openai-gpt-text-custom-metaverse-worlds', 'display_url': 'decrypt.co/123906/openai-…', 'images': [{'url': 'https://pbs.twimg.com/news_img/1640036655863066625/TMBHV8aN?format=jpg&name=orig', 'width': 1024, 'height': 512}, {'url': 'https://pbs.twimg.com/news_img/1640036655863066625/TMBHV8aN?format=jpg&name=150x150', 'width': 150, 'height': 150}], 'status': 200, 'title': 'OpenAI’s GPT Is Helping Turn Text Into Custom Metaverse Worlds - Decrypt', 'description': 'Web3 metaverse platform Oncyber is adding an AI tool that lets users change up 3D spaces by typing out ideas.', 'unwound_url': 'https://decrypt.co/123906/openai-gpt-text-custom-metaverse-worlds'}]}  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   {'annotations': [{'start': 0, 'end': 6, 'probability': 0.8909, 'type': 'Other', 'normalized_text': 'ChatGTP'}, {'start': 9, 'end': 13, 'probability': 0.7721, 'type': 'Other', 'normalized_text': 'GPT-4'}]}  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            {'annotations': [{'start': 77, 'end': 79, 'probability': 0.5177, 'type': 'Other', 'normalized_text': 'GPU'}], 'mentions': [{'start': 0, 'end': 10, 'username': 'EDUreboot', 'id': '779536468708425729'}, {'start': 11, 'end': 26, 'username': 'michalkosinski', 'id': '52401341'}]}  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      {'annotations': [{'start': 9, 'end': 12, 'probability': 0.4664, 'type': 'Other', 'normalized_text': 'RNDR'}, {'start': 102, 'end': 104, 'probability': 0.5316, 'type': 'Other', 'normalized_text': 'GPT'}, {'start': 107, 'end': 110, 'probability': 0.6255, 'type': 'Other', 'normalized_text': 'USDC'}, {'start': 113, 'end': 127, 'probability': 0.4939, 'type': 'Other', 'normalized_text': 'cryptocommunity'}, {'start': 130, 'end': 136, 'probability': 0.6913, 'type': 'Other', 'normalized_text': 'btcusdt'}, {'start': 167, 'end': 170, 'probability': 0.5509, 'type': 'Other', 'normalized_text': 'RNDR'}], 'hashtags': [{'start': 2, 'end': 7, 'tag': 'PUMP'}, {'start': 97, 'end': 100, 'tag': 'ai'}, {'start': 101, 'end': 105, 'tag': 'GPT'}, {'start': 106, 'end': 111, 'tag': 'USDC'}, {'start': 112, 'end': 128, 'tag': 'cryptocommunity'}, {'start': 129, 'end': 137, 'tag': 'btcusdt'}, {'start': 138, 'end': 147, 'tag': 'altcoins'}, {'start': 148, 'end': 156, 'tag': 'finance'}, {'start': 157, 'end': 165, 'tag': 'binance'}, {'start': 166, 'end': 171, 'tag': 'RNDR'}], 'urls': [{'start': 172, 'end': 195, 'url': 'https://t.co/hKojs3Yvfi', 'expanded_url': 'https://twitter.com/TraderJetBot/status/1636880010899496965/photo/1', 'display_url': 'pic.twitter.com/hKojs3Yvfi', 'media_key': '3_1636880009897086977'}], 'cashtags': [{'start': 8, 'end': 13, 'tag': 'RNDR'}]}  \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ...  \n",
       "85195  {'hashtags': [{'start': 71, 'end': 75, 'tag': 'x27'}, {'start': 91, 'end': 95, 'tag': 'x27'}], 'urls': [{'start': 8, 'end': 31, 'url': 'https://t.co/DPpe0zc41v', 'expanded_url': 'https://openai.com/research/gpt-4', 'display_url': 'openai.com/research/gpt-4', 'images': [{'url': 'https://pbs.twimg.com/news_img/1648709685430861825/HD4XdKTK?format=jpg&name=orig', 'width': 2048, 'height': 1367}, {'url': 'https://pbs.twimg.com/news_img/1648709685430861825/HD4XdKTK?format=jpg&name=150x150', 'width': 150, 'height': 150}], 'status': 200, 'title': 'GPT-4', 'description': 'We’ve created GPT-4, the latest milestone in OpenAI’s effort in scaling up deep learning. GPT-4 is a large multimodal model (accepting image and text inputs, emitting text outputs) that, while less capable than humans in many real-world scenarios, exhibits human-level performance on various professional and academic benchmarks.', 'unwound_url': 'https://openai.com/research/gpt-4'}, {'start': 129, 'end': 152, 'url': 'https://t.co/6eeh9j7xye', 'expanded_url': 'https://gitlab.com/kalilinux/kali-purple/documentation/-/wikis/home', 'display_url': 'gitlab.com/kalilinux/kali…', 'images': [{'url': 'https://pbs.twimg.com/news_img/1645910119450828802/Bh4sx5u8?format=png&name=orig', 'width': 246, 'height': 200}, {'url': 'https://pbs.twimg.com/news_img/1645910119450828802/Bh4sx5u8?format=png&name=150x150', 'width': 150, 'height': 150}], 'status': 200, 'title': 'Home · Wiki · Kali Linux / kali-purple / Documentation · GitLab', 'description': 'The ultimate SOC-in-a-box community project', 'unwound_url': 'https://gitlab.com/kalilinux/kali-purple/documentation/-/wikis/home'}, {'start': 184, 'end': 207, 'url': 'https://t.co/46QTix3v7q', 'expanded_url': 'https://github.com/anysphere/gpt-4-for-code', 'display_url': 'github.com/anysphere/gpt-…', 'images': [{'url': 'https://pbs.twimg.com/news_img/1644410478784032768/MX7wyH9A?format=jpg&name=orig', 'width': 1200, 'height': 600}, {'url': 'https://pbs.twimg.com/news_img/1644410478784032768/MX7wyH9A?format=jpg&name=150x150', 'width': 150, 'height': 150}], 'status': 200, 'title': 'GitHub - anysphere/gpt-4-for-code: Some examples of GPT-4 for code!', 'description': 'Some examples of GPT-4 for code! Contribute to anysphere/gpt-4-for-code development by creating an account on GitHub.', 'unwound_url': 'https://github.com/anysphere/gpt-4-for-code'}], 'annotations': [{'start': 0, 'end': 4, 'probability': 0.6125, 'type': 'Other', 'normalized_text': 'GPT-4'}, {'start': 33, 'end': 42, 'probability': 0.7377, 'type': 'Other', 'normalized_text': 'Kali Linux'}, {'start': 48, 'end': 48, 'probability': 0.5643, 'type': 'Other', 'normalized_text': '.'}, {'start': 154, 'end': 156, 'probability': 0.4807, 'type': 'Other', 'normalized_text': 'GPT'}]}  \n",
       "85196                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     {'mentions': [{'start': 0, 'end': 16, 'username': 'jordanbpeterson', 'id': '95092020'}], 'annotations': [{'start': 17, 'end': 21, 'probability': 0.896, 'type': 'Other', 'normalized_text': 'GPT-4'}]}  \n",
       "85197                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                {'hashtags': [{'start': 107, 'end': 115, 'tag': 'ChatGPT'}, {'start': 143, 'end': 152, 'tag': 'altcoins'}], 'annotations': [{'start': 0, 'end': 4, 'probability': 0.7424, 'type': 'Other', 'normalized_text': 'GPT-4'}, {'start': 108, 'end': 114, 'probability': 0.6574, 'type': 'Other', 'normalized_text': 'ChatGPT'}, {'start': 144, 'end': 151, 'probability': 0.5616, 'type': 'Other', 'normalized_text': 'altcoins'}, {'start': 177, 'end': 179, 'probability': 0.4255, 'type': 'Other', 'normalized_text': 'ICP'}, {'start': 183, 'end': 185, 'probability': 0.4456, 'type': 'Other', 'normalized_text': 'TAO'}, {'start': 189, 'end': 191, 'probability': 0.461, 'type': 'Other', 'normalized_text': 'FET'}, {'start': 195, 'end': 198, 'probability': 0.5441, 'type': 'Other', 'normalized_text': 'AGIX'}, {'start': 202, 'end': 204, 'probability': 0.5917, 'type': 'Other', 'normalized_text': 'DAG'}, {'start': 208, 'end': 210, 'probability': 0.5943, 'type': 'Other', 'normalized_text': 'VXV'}, {'start': 213, 'end': 217, 'probability': 0.5958, 'type': 'Other', 'normalized_text': 'OCEAN'}, {'start': 220, 'end': 222, 'probability': 0.4641, 'type': 'Other', 'normalized_text': 'NMR'}, {'start': 225, 'end': 227, 'probability': 0.5135, 'type': 'Other', 'normalized_text': 'GRT'}, {'start': 230, 'end': 233, 'probability': 0.5169, 'type': 'Other', 'normalized_text': 'HERA'}, {'start': 236, 'end': 238, 'probability': 0.4251, 'type': 'Other', 'normalized_text': 'DKA'}, {'start': 241, 'end': 244, 'probability': 0.478, 'type': 'Other', 'normalized_text': 'CTXC'}, {'start': 247, 'end': 249, 'probability': 0.3636, 'type': 'Other', 'normalized_text': 'DBC'}], 'cashtags': [{'start': 176, 'end': 180, 'tag': 'ICP'}, {'start': 182, 'end': 186, 'tag': 'TAO'}, {'start': 188, 'end': 192, 'tag': 'FET'}, {'start': 194, 'end': 199, 'tag': 'AGIX'}, {'start': 201, 'end': 205, 'tag': 'DAG'}, {'start': 207, 'end': 211, 'tag': 'VXV'}, {'start': 212, 'end': 218, 'tag': 'OCEAN'}, {'start': 219, 'end': 223, 'tag': 'NMR'}, {'start': 224, 'end': 228, 'tag': 'GRT'}, {'start': 229, 'end': 234, 'tag': 'HERA'}, {'start': 235, 'end': 239, 'tag': 'DKA'}, {'start': 240, 'end': 245, 'tag': 'CTXC'}, {'start': 246, 'end': 250, 'tag': 'DBC'}]}  \n",
       "85198                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               {'urls': [{'start': 29, 'end': 52, 'url': 'https://t.co/ZkEIkfcMAd', 'expanded_url': 'https://openai.com/customer-stories/be-my-eyes', 'display_url': 'openai.com/customer-stori…', 'images': [{'url': 'https://pbs.twimg.com/news_img/1646723707015168003/TgIkIOoZ?format=jpg&name=orig', 'width': 1290, 'height': 1290}, {'url': 'https://pbs.twimg.com/news_img/1646723707015168003/TgIkIOoZ?format=jpg&name=150x150', 'width': 150, 'height': 150}], 'status': 200, 'title': 'Be My Eyes', 'description': 'Be My Eyes uses GPT-4 to transform visual accessibility.', 'unwound_url': 'https://openai.com/customer-stories/be-my-eyes'}], 'annotations': [{'start': 0, 'end': 9, 'probability': 0.9768, 'type': 'Other', 'normalized_text': 'Be My Eyes'}, {'start': 22, 'end': 26, 'probability': 0.9014, 'type': 'Other', 'normalized_text': 'GPT-4'}]}  \n",
       "85199                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    {'urls': [{'start': 40, 'end': 63, 'url': 'https://t.co/TOStSF7FP8', 'expanded_url': 'https://twitter.com/xdmbna/status/1635792927963095040/photo/1', 'display_url': 'pic.twitter.com/TOStSF7FP8', 'media_key': '3_1635792924225961985'}], 'annotations': [{'start': 0, 'end': 4, 'probability': 0.9456, 'type': 'Other', 'normalized_text': 'GPT-4'}]}  \n",
       "\n",
       "[85200 rows x 14 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read file\n",
    "df = DB.fetch(table_name='after_4', path=fname_db)\n",
    "df.columns = col_name\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630e6b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

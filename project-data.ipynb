{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16cf817d",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cad5f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.2.4)\n",
      "Requirement already satisfied: numpy in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (1.22.4)\n",
      "Requirement already satisfied: seaborn in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (0.11.1)\n",
      "Requirement already satisfied: matplotlib in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (3.3.4)\n",
      "Requirement already satisfied: sqlalchemy==1.4.39 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (1.4.39)\n",
      "Requirement already satisfied: loguru==0.6.0 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (0.6.0)\n",
      "Requirement already satisfied: networkx==2.6.3 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (2.6.3)\n",
      "Requirement already satisfied: transformers in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 8)) (4.26.1)\n",
      "Requirement already satisfied: wordcloud==1.8.2.2 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 9)) (1.8.2.2)\n",
      "Requirement already satisfied: umap-learn in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 10)) (0.5.3)\n",
      "Requirement already satisfied: pyLDAvis==2.1.2 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 11)) (2.1.2)\n",
      "Requirement already satisfied: holoviews in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 12)) (1.15.4)\n",
      "Requirement already satisfied: bokeh in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 13)) (2.4.3)\n",
      "Requirement already satisfied: sklearn in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 14)) (0.0.post1)\n",
      "Requirement already satisfied: openai in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 15)) (0.27.0)\n",
      "Requirement already satisfied: wandb in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 16)) (0.13.10)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from sqlalchemy==1.4.39->-r requirements.txt (line 5)) (1.0.0)\n",
      "Requirement already satisfied: pillow in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from wordcloud==1.8.2.2->-r requirements.txt (line 9)) (8.2.0)\n",
      "Requirement already satisfied: joblib>=0.8.4 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from pyLDAvis==2.1.2->-r requirements.txt (line 11)) (1.0.1)\n",
      "Requirement already satisfied: jinja2>=2.7.2 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from pyLDAvis==2.1.2->-r requirements.txt (line 11)) (3.0.2)\n",
      "Requirement already satisfied: pytest in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from pyLDAvis==2.1.2->-r requirements.txt (line 11)) (6.2.3)\n",
      "Requirement already satisfied: scipy>=0.18.0 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from pyLDAvis==2.1.2->-r requirements.txt (line 11)) (1.6.2)\n",
      "Requirement already satisfied: numexpr in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from pyLDAvis==2.1.2->-r requirements.txt (line 11)) (2.7.3)\n",
      "Requirement already satisfied: wheel>=0.23.0 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from pyLDAvis==2.1.2->-r requirements.txt (line 11)) (0.36.2)\n",
      "Requirement already satisfied: funcy in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from pyLDAvis==2.1.2->-r requirements.txt (line 11)) (1.18)\n",
      "Requirement already satisfied: future in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from pyLDAvis==2.1.2->-r requirements.txt (line 11)) (0.18.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from pandas->-r requirements.txt (line 1)) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from pandas->-r requirements.txt (line 1)) (2021.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 4)) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 4)) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 8)) (0.12.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 8)) (5.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 8)) (4.59.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 8)) (2021.4.4)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 8)) (0.13.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 8)) (21.3)\n",
      "Requirement already satisfied: requests in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 8)) (2.28.0)\n",
      "Requirement already satisfied: filelock in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 8)) (3.0.12)\n",
      "Requirement already satisfied: numba>=0.49 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from umap-learn->-r requirements.txt (line 10)) (0.53.1)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from umap-learn->-r requirements.txt (line 10)) (0.5.8)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from umap-learn->-r requirements.txt (line 10)) (0.24.1)\n",
      "Requirement already satisfied: colorcet in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from holoviews->-r requirements.txt (line 12)) (3.0.1)\n",
      "Requirement already satisfied: panel>=0.13.1 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from holoviews->-r requirements.txt (line 12)) (0.14.4)\n",
      "Requirement already satisfied: pyviz-comms>=0.7.4 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from holoviews->-r requirements.txt (line 12)) (2.2.1)\n",
      "Requirement already satisfied: param<2.0,>=1.9.3 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from holoviews->-r requirements.txt (line 12)) (1.12.3)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from bokeh->-r requirements.txt (line 13)) (4.5.0)\n",
      "Requirement already satisfied: tornado>=5.1 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from bokeh->-r requirements.txt (line 13)) (6.1)\n",
      "Requirement already satisfied: aiohttp in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from openai->-r requirements.txt (line 15)) (3.8.4)\n",
      "Requirement already satisfied: setuptools in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 16)) (52.0.0.post20210125)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 16)) (1.4.4)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 16)) (7.1.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 16)) (3.19.6)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 16)) (1.16.0)\n",
      "Requirement already satisfied: pathtools in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 16)) (0.1.2)\n",
      "Requirement already satisfied: setproctitle in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 16)) (1.3.2)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 16)) (3.1.31)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 16)) (0.4.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from wandb->-r requirements.txt (line 16)) (5.8.0)\n",
      "Requirement already satisfied: six in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from cycler>=0.10->matplotlib->-r requirements.txt (line 4)) (1.15.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from GitPython>=1.0.0->wandb->-r requirements.txt (line 16)) (4.0.10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from jinja2>=2.7.2->pyLDAvis==2.1.2->-r requirements.txt (line 11)) (2.0.1)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from numba>=0.49->umap-learn->-r requirements.txt (line 10)) (0.36.0)\n",
      "Requirement already satisfied: bleach in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from panel>=0.13.1->holoviews->-r requirements.txt (line 12)) (3.3.0)\n",
      "Requirement already satisfied: markdown in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from panel>=0.13.1->holoviews->-r requirements.txt (line 12)) (3.4.1)\n",
      "Requirement already satisfied: pyct>=0.4.4 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from panel>=0.13.1->holoviews->-r requirements.txt (line 12)) (0.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers->-r requirements.txt (line 8)) (2020.12.5)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers->-r requirements.txt (line 8)) (2.0.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers->-r requirements.txt (line 8)) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers->-r requirements.txt (line 8)) (2.10)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.22->umap-learn->-r requirements.txt (line 10)) (2.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from aiohttp->openai->-r requirements.txt (line 15)) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from aiohttp->openai->-r requirements.txt (line 15)) (1.8.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from aiohttp->openai->-r requirements.txt (line 15)) (20.3.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from aiohttp->openai->-r requirements.txt (line 15)) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from aiohttp->openai->-r requirements.txt (line 15)) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from aiohttp->openai->-r requirements.txt (line 15)) (1.3.3)\n",
      "Requirement already satisfied: iniconfig in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from pytest->pyLDAvis==2.1.2->-r requirements.txt (line 11)) (1.1.1)\n",
      "Requirement already satisfied: pluggy<1.0.0a1,>=0.12 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from pytest->pyLDAvis==2.1.2->-r requirements.txt (line 11)) (0.13.1)\n",
      "Requirement already satisfied: py>=1.8.2 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from pytest->pyLDAvis==2.1.2->-r requirements.txt (line 11)) (1.10.0)\n",
      "Requirement already satisfied: toml in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from pytest->pyLDAvis==2.1.2->-r requirements.txt (line 11)) (0.10.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb->-r requirements.txt (line 16)) (5.0.0)\n",
      "Requirement already satisfied: webencodings in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from bleach->panel>=0.13.1->holoviews->-r requirements.txt (line 12)) (0.5.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from markdown->panel>=0.13.1->holoviews->-r requirements.txt (line 12)) (4.12.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/esther/opt/anaconda3/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown->panel>=0.13.1->holoviews->-r requirements.txt (line 12)) (3.4.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95359550",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from scripts.api import *\n",
    "\n",
    "from scripts.create_graph import *\n",
    "import networkx as nx\n",
    "import networkx.algorithms.community as nx_comm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7f3ea0",
   "metadata": {},
   "source": [
    "# Fetch tweets with specific keywords and dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37508445",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_db = f\"data/data1\"  \n",
    "target_total = 10000\n",
    "keyword = 'chatGPT'\n",
    "start_date = '2019-01-01'   \n",
    "end_date = '2023-04-01'\n",
    "retweets = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "efe54801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-19 21:32:09.530] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-19 21:32:11.373] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-19 21:32:13.014] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-19 21:32:14.857] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-19 21:32:16.438] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-19 21:32:18.134] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-19 21:32:19.832] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-19 21:32:21.406] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-19 21:32:23.253] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-19 21:32:24.890] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-19 21:32:26.529] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-19 21:32:28.372] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-19 21:32:30.213] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-19 21:32:31.957] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-19 21:32:33.903] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-19 21:32:35.826] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-19 21:32:37.704] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-19 21:32:39.429] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-19 21:32:41.067] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-19 21:32:42.910] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-19 21:32:44.690] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-19 21:32:46.594] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-19 21:32:48.417] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-19 21:32:50.491] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-19 21:32:52.333] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-19 21:32:54.177] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-19 21:32:56.224] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-19 21:32:58.475] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-19 21:33:00.321] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-19 21:33:02.118] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-19 21:33:03.802] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-19 21:33:05.888] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-19 21:33:07.741] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-19 21:33:09.522] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-19 21:33:11.968] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-19 21:33:13.652] [INFO] [api:fetch:236] Fetched 95 tweets\n",
      "[2023-04-19 21:33:15.434] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-19 21:33:17.073] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-19 21:33:19.365] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-19 21:33:21.415] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-19 21:33:23.256] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-19 21:33:25.103] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-19 21:33:26.944] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-19 21:33:28.793] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-19 21:33:30.840] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-19 21:33:33.091] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-19 21:33:34.935] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-19 21:33:36.964] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-19 21:33:39.028] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-19 21:33:40.870] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-19 21:33:42.712] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-19 21:33:44.397] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-19 21:33:47.014] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-19 21:33:48.855] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-19 21:33:50.703] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-19 21:33:52.544] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-19 21:33:54.592] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-19 21:33:56.637] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-19 21:33:58.378] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-19 21:34:00.327] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-19 21:34:02.376] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-19 21:34:04.217] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-19 21:34:06.262] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-19 21:34:08.108] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-19 21:34:10.155] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-19 21:34:11.990] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-19 21:34:13.840] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-19 21:34:15.682] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-19 21:34:17.630] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-19 21:34:19.570] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-19 21:34:21.229] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-19 21:34:23.053] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-19 21:34:24.755] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-19 21:34:26.533] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-19 21:34:28.583] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-19 21:34:30.628] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-19 21:34:32.259] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-19 21:34:34.112] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-19 21:34:35.952] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-19 21:34:37.800] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-19 21:34:39.536] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-19 21:34:41.250] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-19 21:34:42.983] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-19 21:34:44.895] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-19 21:34:46.807] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-19 21:34:48.649] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-19 21:34:50.495] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-19 21:34:52.542] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-19 21:34:54.997] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-19 21:34:56.802] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-19 21:34:58.683] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-19 21:35:00.428] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-19 21:35:02.374] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-19 21:35:04.216] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-19 21:35:06.659] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-19 21:35:08.719] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-19 21:35:10.563] [INFO] [api:fetch:236] Fetched 97 tweets\n",
      "[2023-04-19 21:35:12.254] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-19 21:35:14.052] [INFO] [api:fetch:236] Fetched 99 tweets\n",
      "[2023-04-19 21:35:15.938] [INFO] [api:fetch:236] Fetched 98 tweets\n",
      "[2023-04-19 21:35:17.564] [INFO] [api:fetch:236] Fetched 96 tweets\n",
      "[2023-04-19 21:35:19.370] [INFO] [api:fetch:236] Fetched 100 tweets\n",
      "[2023-04-19 21:35:19.787] [INFO] [api:write:61] Writing 10028 rows to table chatGPT_only\n"
     ]
    }
   ],
   "source": [
    "df_keyword = History.fetch(keyword=keyword, start_date= start_date, end_date= end_date, \n",
    "                    target_total=target_total, retweets=retweets)       \n",
    "DB.write(table_name='chatGPT_only', path=fname_db, data=df_keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a2f8444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>geo</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-31T23:59:52.000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>🔥Hey Guys, #ZenithSwap has launched at just $ 55,000 USD Marketcap. The ChatGPT of DEX - Reimagining DeFi with AI-Powered Yield Farming. Now at 4X. Lot of up potential at such low marketcap.🔥😇 $ARB $ZSP #Arbitrum https://t.co/MXDS0JOL8Q</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1641953488900096000</td>\n",
       "      <td>1577123038184628225</td>\n",
       "      <td>1641953488900096000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>{'annotations': [{'start': 12, 'end': 21, 'probability': 0.3675, 'type': 'Organization', 'normalized_text': 'ZenithSwap'}, {'start': 194, 'end': 196, 'probability': 0.5827, 'type': 'Organization', 'normalized_text': 'ARB'}, {'start': 199, 'end': 201, 'probability': 0.4959, 'type': 'Other', 'normalized_text': 'ZSP'}, {'start': 204, 'end': 211, 'probability': 0.3654, 'type': 'Other', 'normalized_text': 'Arbitrum'}], 'hashtags': [{'start': 11, 'end': 22, 'tag': 'ZenithSwap'}, {'start': 203, 'end': 212, 'tag': 'Arbitrum'}], 'cashtags': [{'start': 193, 'end': 197, 'tag': 'ARB'}, {'start': 198, 'end': 202, 'tag': 'ZSP'}], 'urls': [{'start': 213, 'end': 236, 'url': 'https://t.co/MXDS0JOL8Q', 'expanded_url': 'https://wn.nr/Wr4QmbH', 'display_url': 'wn.nr/Wr4QmbH', 'images': [{'url': 'https://pbs.twimg.com/news_img/1641845770872815616/01vWUe0h?format=jpg&amp;name=orig', 'width': 3840, 'height': 2160}, {'url': 'https://pbs.twimg.com/news_img/1641845770872815616/01vWUe0h?format=jpg&amp;name=150x150', 'width': 150, 'height': 150}], 'status': 200, 'title': 'ZenithSwap Airdrop upto $ 36K | The ChatGPT of DEX World', 'description': \"The ChatGPT of DEX - Reimagining Decentralized Finance with AI-Powered Yield Farming. Zero fee for a limited time. Checkout Whitepaper Launching on SuperHyped ArbitrumPad Do you know ZenithSwap is raising just 35 ETH from Public Sale and listing at just 55k USD Marketcap. Apply for Whitelist =================================================== Time: 10:00 AM 25th March'23 – 3rd April'23 Distribution: 1 Week After IDO * Total Airdrop Value: $ 36K Winner: 3,000 lucky winners completing all tasks Reward: 2000 $ZSP/Winner (~12$ at IDO price) =================================================== Website Twitter Telegram \\u200b Reward Distribution: 2 PM UTC, 3rd March 2023\", 'unwound_url': 'https://gleam.io/R3Nif/zenithswap-airdrop-contest-win-up-to-36k?gsr=R3Nif-SddhJHJgWC'}]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-31T23:59:48.000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>🇮🇹 ChatGPT banned in Italy over privacy concerns 😳</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1641953472357584896</td>\n",
       "      <td>1261563663267356672</td>\n",
       "      <td>1641953472357584896</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>{'annotations': [{'start': 3, 'end': 9, 'probability': 0.7481, 'type': 'Other', 'normalized_text': 'ChatGPT'}, {'start': 21, 'end': 25, 'probability': 0.9714, 'type': 'Place', 'normalized_text': 'Italy'}]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-31T23:59:47.000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>The wait is over, ChatGpt integrated with Figma!!\\nhttps://t.co/bDs5J4yHSH</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1641953468725477377</td>\n",
       "      <td>717234885019172865</td>\n",
       "      <td>1641953468725477377</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>{'annotations': [{'start': 18, 'end': 24, 'probability': 0.5372, 'type': 'Other', 'normalized_text': 'ChatGpt'}, {'start': 42, 'end': 46, 'probability': 0.8718, 'type': 'Other', 'normalized_text': 'Figma'}], 'urls': [{'start': 50, 'end': 73, 'url': 'https://t.co/bDs5J4yHSH', 'expanded_url': 'https://www.olexdsgn.com/figgpt', 'display_url': 'olexdsgn.com/figgpt', 'images': [{'url': 'https://pbs.twimg.com/news_img/1635100406627061760/glyg_H7o?format=png&amp;name=orig', 'width': 1020, 'height': 630}, {'url': 'https://pbs.twimg.com/news_img/1635100406627061760/glyg_H7o?format=png&amp;name=150x150', 'width': 150, 'height': 150}], 'status': 200, 'title': 'FigGPT Figma Plugin', 'description': 'Amplify your workflow in Figma with AI', 'unwound_url': 'https://www.olexdsgn.com/figgpt'}]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-31T23:59:42.000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>Many VC firms are good at putting out content. But with chatgpt, this is becoming commoditized.\\n\\n@generalcatalyst is seeing the future a little differently than its peers. Second offering I’m impressed with. \\n\\nFirst: https://t.co/7Dp9tEYkJg</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1641953446323691520</td>\n",
       "      <td>15008460</td>\n",
       "      <td>1641952252247302145</td>\n",
       "      <td>15008460</td>\n",
       "      <td>nan</td>\n",
       "      <td>{'mentions': [{'start': 97, 'end': 113, 'username': 'generalcatalyst', 'id': '31099876'}], 'urls': [{'start': 217, 'end': 240, 'url': 'https://t.co/7Dp9tEYkJg', 'expanded_url': 'https://twitter.com/ashwinl/status/1624510174261317632', 'display_url': 'twitter.com/ashwinl/status…'}]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-31T23:59:41.000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>🚨Sell Now!🚨\\n💰#Binance Spot💰\\n⬇ Recommendation: #Short 🔴\\nTicker:  #ADXBUSD\\nTime Interval:  30min\\nLast Price: 0.2045\\n🔴 RSI: 93.5\\n\\nPowered by #ChatGPT\\n\\n$ADX\\n#ADX\\n\\nWhat are you gonna do?\\n   LONG         WAIT           SHORT\\n        👇               👇               👇</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1641953443165376512</td>\n",
       "      <td>1594551708788887552</td>\n",
       "      <td>1641953443165376512</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>{'hashtags': [{'start': 13, 'end': 21, 'tag': 'Binance'}, {'start': 46, 'end': 52, 'tag': 'Short'}, {'start': 64, 'end': 72, 'tag': 'ADXBUSD'}, {'start': 138, 'end': 146, 'tag': 'ChatGPT'}, {'start': 153, 'end': 157, 'tag': 'ADX'}], 'cashtags': [{'start': 148, 'end': 152, 'tag': 'ADX'}]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2023-03-31T16:41:27.000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>Italy has become the first Western country to block advanced chatbot ChatGPT.\\n\\nThe Italian data-protection authority said there were privacy concerns relating to the model, which was created by US start-up OpenAI and is backed by M…https://t.co/XzPDEoX0nF https://t.co/X9eWAhKa0M</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1641843157175357445</td>\n",
       "      <td>1584571812708552705</td>\n",
       "      <td>1641843157175357445</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>{'urls': [{'start': 232, 'end': 255, 'url': 'https://t.co/XzPDEoX0nF', 'expanded_url': 'https://lnkd.in/emQZSq_9', 'display_url': 'lnkd.in/emQZSq_9', 'images': [{'url': 'https://pbs.twimg.com/news_img/1641843160279023637/by_MbpE6?format=jpg&amp;name=orig', 'width': 1024, 'height': 576}, {'url': 'https://pbs.twimg.com/news_img/1641843160279023637/by_MbpE6?format=jpg&amp;name=150x150', 'width': 150, 'height': 150}], 'status': 200, 'title': 'Vince McConville ☘️ on LinkedIn: ChatGPT banned in Italy over privacy concerns', 'description': 'Italy has become the first Western country to block advanced chatbot ChatGPT. The Italian data-protection authority said there were privacy concerns relating…', 'unwound_url': 'https://www.linkedin.com/feed/update/urn:li:share:7047608782507384832'}, {'start': 256, 'end': 279, 'url': 'https://t.co/X9eWAhKa0M', 'expanded_url': 'https://lnkd.in/evzTMtp4', 'display_url': 'lnkd.in/evzTMtp4', 'images': [{'url': 'https://pbs.twimg.com/news_img/1647858371473678338/bqFKvmKY?format=jpg&amp;name=orig', 'width': 1024, 'height': 576}, {'url': 'https://pbs.twimg.com/news_img/1647858371473678338/bqFKvmKY?format=jpg&amp;name=150x150', 'width': 150, 'height': 150}], 'status': 200, 'title': 'ChatGPT banned in Italy over privacy concerns', 'description': \"The country's data-protection regulator has serious privacy concerns over the technology.\", 'unwound_url': 'https://www.bbc.co.uk/news/technology-65139406'}], 'annotations': [{'start': 0, 'end': 4, 'probability': 0.9864, 'type': 'Place', 'normalized_text': 'Italy'}, {'start': 69, 'end': 75, 'probability': 0.5148, 'type': 'Other', 'normalized_text': 'ChatGPT'}, {'start': 194, 'end': 195, 'probability': 0.9297, 'type': 'Place', 'normalized_text': 'US'}, {'start': 206, 'end': 211, 'probability': 0.6209, 'type': 'Organization', 'normalized_text': 'OpenAI'}]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2023-03-31T16:41:21.000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>Mamma Mia! Italy’s temporarily banned ChatGPT due to alleged GDPR privacy violations including no age verifications, no filters for under 13s, and lack of accuracy. \\n\\n📸 credit: @linasbeliunas on LinkedIn https://t.co/h316Mj56Dz</td>\n",
       "      <td>en</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1641843134043652107</td>\n",
       "      <td>883125325290393601</td>\n",
       "      <td>1641843134043652107</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>{'urls': [{'start': 204, 'end': 227, 'url': 'https://t.co/h316Mj56Dz', 'expanded_url': 'https://twitter.com/kaitiezhee/status/1641843134043652107/photo/1', 'display_url': 'pic.twitter.com/h316Mj56Dz', 'media_key': '3_1641843129815904257'}], 'annotations': [{'start': 0, 'end': 8, 'probability': 0.6219, 'type': 'Other', 'normalized_text': 'Mamma Mia'}, {'start': 11, 'end': 15, 'probability': 0.967, 'type': 'Place', 'normalized_text': 'Italy'}, {'start': 38, 'end': 44, 'probability': 0.7256, 'type': 'Other', 'normalized_text': 'ChatGPT'}, {'start': 61, 'end': 64, 'probability': 0.5261, 'type': 'Other', 'normalized_text': 'GDPR'}, {'start': 195, 'end': 202, 'probability': 0.5671, 'type': 'Other', 'normalized_text': 'LinkedIn'}], 'mentions': [{'start': 177, 'end': 191, 'username': 'linasbeliunas', 'id': '1294016945411563523'}]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2023-03-31T16:41:21.000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>ChatGPT: pineapple belongs on pizza.\\n\\nItaly: https://t.co/008B9TWrt3</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1641843133393534984</td>\n",
       "      <td>1444823243865608195</td>\n",
       "      <td>1641843133393534984</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>{'urls': [{'start': 45, 'end': 68, 'url': 'https://t.co/008B9TWrt3', 'expanded_url': 'https://twitter.com/pyra_m1d/status/1641843133393534984/photo/1', 'display_url': 'pic.twitter.com/008B9TWrt3', 'media_key': '16_1641843122291478530'}], 'annotations': [{'start': 0, 'end': 6, 'probability': 0.7101, 'type': 'Other', 'normalized_text': 'ChatGPT'}, {'start': 38, 'end': 42, 'probability': 0.9446, 'type': 'Place', 'normalized_text': 'Italy'}]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2023-03-31T16:41:20.000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>Determining whether text has come from artificial intelligence models like ChatGPT might be impossible to do reliably, according to a new mathematical proof.\\n\\nhttps://t.co/0u0EwGMZjz</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1641843130117783556</td>\n",
       "      <td>112981790</td>\n",
       "      <td>1641843130117783556</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>{'urls': [{'start': 159, 'end': 182, 'url': 'https://t.co/0u0EwGMZjz', 'expanded_url': 'https://www.newscientist.com/article/2366824-reliably-detecting-ai-generated-text-is-mathematically-impossible/', 'display_url': 'newscientist.com/article/236682…', 'images': [{'url': 'https://pbs.twimg.com/news_img/1646847931176067072/-tGq--PC?format=jpg&amp;name=orig', 'width': 1350, 'height': 900}, {'url': 'https://pbs.twimg.com/news_img/1646847931176067072/-tGq--PC?format=jpg&amp;name=150x150', 'width': 150, 'height': 150}], 'status': 200, 'title': 'Reliably detecting AI-generated text is mathematically impossible | New Scientist', 'description': 'The ease with which artificial intelligence can generate and paraphrase language means that detectors to spot AI content will only be as accurate as flipping a coin', 'unwound_url': 'https://www.newscientist.com/article/2366824-reliably-detecting-ai-generated-text-is-mathematically-impossible/'}], 'annotations': [{'start': 75, 'end': 81, 'probability': 0.9415, 'type': 'Other', 'normalized_text': 'ChatGPT'}]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2023-03-31T16:41:18.000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>fuck chatgpt actually</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1641843121431379979</td>\n",
       "      <td>1610756209384034320</td>\n",
       "      <td>1641843121431379979</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10028 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  created_at screen_name  \\\n",
       "0   2023-03-31T23:59:52.000Z        None   \n",
       "1   2023-03-31T23:59:48.000Z        None   \n",
       "2   2023-03-31T23:59:47.000Z        None   \n",
       "3   2023-03-31T23:59:42.000Z        None   \n",
       "4   2023-03-31T23:59:41.000Z        None   \n",
       "..                       ...         ...   \n",
       "95  2023-03-31T16:41:27.000Z        None   \n",
       "96  2023-03-31T16:41:21.000Z        None   \n",
       "97  2023-03-31T16:41:21.000Z        None   \n",
       "98  2023-03-31T16:41:20.000Z        None   \n",
       "99  2023-03-31T16:41:18.000Z        None   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                         text  \\\n",
       "0                                                🔥Hey Guys, #ZenithSwap has launched at just $ 55,000 USD Marketcap. The ChatGPT of DEX - Reimagining DeFi with AI-Powered Yield Farming. Now at 4X. Lot of up potential at such low marketcap.🔥😇 $ARB $ZSP #Arbitrum https://t.co/MXDS0JOL8Q   \n",
       "1                                                                                                                                                                                                                                          🇮🇹 ChatGPT banned in Italy over privacy concerns 😳   \n",
       "2                                                                                                                                                                                                                  The wait is over, ChatGpt integrated with Figma!!\\nhttps://t.co/bDs5J4yHSH   \n",
       "3                                        Many VC firms are good at putting out content. But with chatgpt, this is becoming commoditized.\\n\\n@generalcatalyst is seeing the future a little differently than its peers. Second offering I’m impressed with. \\n\\nFirst: https://t.co/7Dp9tEYkJg   \n",
       "4         🚨Sell Now!🚨\\n💰#Binance Spot💰\\n⬇ Recommendation: #Short 🔴\\nTicker:  #ADXBUSD\\nTime Interval:  30min\\nLast Price: 0.2045\\n🔴 RSI: 93.5\\n\\nPowered by #ChatGPT\\n\\n$ADX\\n#ADX\\n\\nWhat are you gonna do?\\n   LONG         WAIT           SHORT\\n        👇               👇               👇   \n",
       "..                                                                                                                                                                                                                                                                                        ...   \n",
       "95  Italy has become the first Western country to block advanced chatbot ChatGPT.\\n\\nThe Italian data-protection authority said there were privacy concerns relating to the model, which was created by US start-up OpenAI and is backed by M…https://t.co/XzPDEoX0nF https://t.co/X9eWAhKa0M   \n",
       "96                                                      Mamma Mia! Italy’s temporarily banned ChatGPT due to alleged GDPR privacy violations including no age verifications, no filters for under 13s, and lack of accuracy. \\n\\n📸 credit: @linasbeliunas on LinkedIn https://t.co/h316Mj56Dz   \n",
       "97                                                                                                                                                                                                                     ChatGPT: pineapple belongs on pizza.\\n\\nItaly: https://t.co/008B9TWrt3   \n",
       "98                                                                                                   Determining whether text has come from artificial intelligence models like ChatGPT might be impossible to do reliably, according to a new mathematical proof.\\n\\nhttps://t.co/0u0EwGMZjz   \n",
       "99                                                                                                                                                                                                                                                                      fuck chatgpt actually   \n",
       "\n",
       "   lang  retweet_count  reply_count  like_count  quote_count  \\\n",
       "0    en              0            0           0            0   \n",
       "1    en              1            0           1            0   \n",
       "2    en              0            0           1            0   \n",
       "3    en              0            0           0            0   \n",
       "4    en              0            0           0            0   \n",
       "..  ...            ...          ...         ...          ...   \n",
       "95   en              0            0           0            0   \n",
       "96   en              3            0           6            1   \n",
       "97   en              0            0           2            0   \n",
       "98   en              0            0           2            0   \n",
       "99   en              0            0           1            0   \n",
       "\n",
       "                     id            author_id      conversation_id  \\\n",
       "0   1641953488900096000  1577123038184628225  1641953488900096000   \n",
       "1   1641953472357584896  1261563663267356672  1641953472357584896   \n",
       "2   1641953468725477377   717234885019172865  1641953468725477377   \n",
       "3   1641953446323691520             15008460  1641952252247302145   \n",
       "4   1641953443165376512  1594551708788887552  1641953443165376512   \n",
       "..                  ...                  ...                  ...   \n",
       "95  1641843157175357445  1584571812708552705  1641843157175357445   \n",
       "96  1641843134043652107   883125325290393601  1641843134043652107   \n",
       "97  1641843133393534984  1444823243865608195  1641843133393534984   \n",
       "98  1641843130117783556            112981790  1641843130117783556   \n",
       "99  1641843121431379979  1610756209384034320  1641843121431379979   \n",
       "\n",
       "   in_reply_to_user_id  geo  \\\n",
       "0                  nan  nan   \n",
       "1                  nan  nan   \n",
       "2                  nan  nan   \n",
       "3             15008460  nan   \n",
       "4                  nan  nan   \n",
       "..                 ...  ...   \n",
       "95                 nan  nan   \n",
       "96                 nan  nan   \n",
       "97                 nan  nan   \n",
       "98                 nan  nan   \n",
       "99                 nan  nan   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               entities  \n",
       "0   {'annotations': [{'start': 12, 'end': 21, 'probability': 0.3675, 'type': 'Organization', 'normalized_text': 'ZenithSwap'}, {'start': 194, 'end': 196, 'probability': 0.5827, 'type': 'Organization', 'normalized_text': 'ARB'}, {'start': 199, 'end': 201, 'probability': 0.4959, 'type': 'Other', 'normalized_text': 'ZSP'}, {'start': 204, 'end': 211, 'probability': 0.3654, 'type': 'Other', 'normalized_text': 'Arbitrum'}], 'hashtags': [{'start': 11, 'end': 22, 'tag': 'ZenithSwap'}, {'start': 203, 'end': 212, 'tag': 'Arbitrum'}], 'cashtags': [{'start': 193, 'end': 197, 'tag': 'ARB'}, {'start': 198, 'end': 202, 'tag': 'ZSP'}], 'urls': [{'start': 213, 'end': 236, 'url': 'https://t.co/MXDS0JOL8Q', 'expanded_url': 'https://wn.nr/Wr4QmbH', 'display_url': 'wn.nr/Wr4QmbH', 'images': [{'url': 'https://pbs.twimg.com/news_img/1641845770872815616/01vWUe0h?format=jpg&name=orig', 'width': 3840, 'height': 2160}, {'url': 'https://pbs.twimg.com/news_img/1641845770872815616/01vWUe0h?format=jpg&name=150x150', 'width': 150, 'height': 150}], 'status': 200, 'title': 'ZenithSwap Airdrop upto $ 36K | The ChatGPT of DEX World', 'description': \"The ChatGPT of DEX - Reimagining Decentralized Finance with AI-Powered Yield Farming. Zero fee for a limited time. Checkout Whitepaper Launching on SuperHyped ArbitrumPad Do you know ZenithSwap is raising just 35 ETH from Public Sale and listing at just 55k USD Marketcap. Apply for Whitelist =================================================== Time: 10:00 AM 25th March'23 – 3rd April'23 Distribution: 1 Week After IDO * Total Airdrop Value: $ 36K Winner: 3,000 lucky winners completing all tasks Reward: 2000 $ZSP/Winner (~12$ at IDO price) =================================================== Website Twitter Telegram \\u200b Reward Distribution: 2 PM UTC, 3rd March 2023\", 'unwound_url': 'https://gleam.io/R3Nif/zenithswap-airdrop-contest-win-up-to-36k?gsr=R3Nif-SddhJHJgWC'}]}  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         {'annotations': [{'start': 3, 'end': 9, 'probability': 0.7481, 'type': 'Other', 'normalized_text': 'ChatGPT'}, {'start': 21, 'end': 25, 'probability': 0.9714, 'type': 'Place', 'normalized_text': 'Italy'}]}  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          {'annotations': [{'start': 18, 'end': 24, 'probability': 0.5372, 'type': 'Other', 'normalized_text': 'ChatGpt'}, {'start': 42, 'end': 46, 'probability': 0.8718, 'type': 'Other', 'normalized_text': 'Figma'}], 'urls': [{'start': 50, 'end': 73, 'url': 'https://t.co/bDs5J4yHSH', 'expanded_url': 'https://www.olexdsgn.com/figgpt', 'display_url': 'olexdsgn.com/figgpt', 'images': [{'url': 'https://pbs.twimg.com/news_img/1635100406627061760/glyg_H7o?format=png&name=orig', 'width': 1020, 'height': 630}, {'url': 'https://pbs.twimg.com/news_img/1635100406627061760/glyg_H7o?format=png&name=150x150', 'width': 150, 'height': 150}], 'status': 200, 'title': 'FigGPT Figma Plugin', 'description': 'Amplify your workflow in Figma with AI', 'unwound_url': 'https://www.olexdsgn.com/figgpt'}]}  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            {'mentions': [{'start': 97, 'end': 113, 'username': 'generalcatalyst', 'id': '31099876'}], 'urls': [{'start': 217, 'end': 240, 'url': 'https://t.co/7Dp9tEYkJg', 'expanded_url': 'https://twitter.com/ashwinl/status/1624510174261317632', 'display_url': 'twitter.com/ashwinl/status…'}]}  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      {'hashtags': [{'start': 13, 'end': 21, 'tag': 'Binance'}, {'start': 46, 'end': 52, 'tag': 'Short'}, {'start': 64, 'end': 72, 'tag': 'ADXBUSD'}, {'start': 138, 'end': 146, 'tag': 'ChatGPT'}, {'start': 153, 'end': 157, 'tag': 'ADX'}], 'cashtags': [{'start': 148, 'end': 152, 'tag': 'ADX'}]}  \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ...  \n",
       "95                                                                              {'urls': [{'start': 232, 'end': 255, 'url': 'https://t.co/XzPDEoX0nF', 'expanded_url': 'https://lnkd.in/emQZSq_9', 'display_url': 'lnkd.in/emQZSq_9', 'images': [{'url': 'https://pbs.twimg.com/news_img/1641843160279023637/by_MbpE6?format=jpg&name=orig', 'width': 1024, 'height': 576}, {'url': 'https://pbs.twimg.com/news_img/1641843160279023637/by_MbpE6?format=jpg&name=150x150', 'width': 150, 'height': 150}], 'status': 200, 'title': 'Vince McConville ☘️ on LinkedIn: ChatGPT banned in Italy over privacy concerns', 'description': 'Italy has become the first Western country to block advanced chatbot ChatGPT. The Italian data-protection authority said there were privacy concerns relating…', 'unwound_url': 'https://www.linkedin.com/feed/update/urn:li:share:7047608782507384832'}, {'start': 256, 'end': 279, 'url': 'https://t.co/X9eWAhKa0M', 'expanded_url': 'https://lnkd.in/evzTMtp4', 'display_url': 'lnkd.in/evzTMtp4', 'images': [{'url': 'https://pbs.twimg.com/news_img/1647858371473678338/bqFKvmKY?format=jpg&name=orig', 'width': 1024, 'height': 576}, {'url': 'https://pbs.twimg.com/news_img/1647858371473678338/bqFKvmKY?format=jpg&name=150x150', 'width': 150, 'height': 150}], 'status': 200, 'title': 'ChatGPT banned in Italy over privacy concerns', 'description': \"The country's data-protection regulator has serious privacy concerns over the technology.\", 'unwound_url': 'https://www.bbc.co.uk/news/technology-65139406'}], 'annotations': [{'start': 0, 'end': 4, 'probability': 0.9864, 'type': 'Place', 'normalized_text': 'Italy'}, {'start': 69, 'end': 75, 'probability': 0.5148, 'type': 'Other', 'normalized_text': 'ChatGPT'}, {'start': 194, 'end': 195, 'probability': 0.9297, 'type': 'Place', 'normalized_text': 'US'}, {'start': 206, 'end': 211, 'probability': 0.6209, 'type': 'Organization', 'normalized_text': 'OpenAI'}]}  \n",
       "96                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   {'urls': [{'start': 204, 'end': 227, 'url': 'https://t.co/h316Mj56Dz', 'expanded_url': 'https://twitter.com/kaitiezhee/status/1641843134043652107/photo/1', 'display_url': 'pic.twitter.com/h316Mj56Dz', 'media_key': '3_1641843129815904257'}], 'annotations': [{'start': 0, 'end': 8, 'probability': 0.6219, 'type': 'Other', 'normalized_text': 'Mamma Mia'}, {'start': 11, 'end': 15, 'probability': 0.967, 'type': 'Place', 'normalized_text': 'Italy'}, {'start': 38, 'end': 44, 'probability': 0.7256, 'type': 'Other', 'normalized_text': 'ChatGPT'}, {'start': 61, 'end': 64, 'probability': 0.5261, 'type': 'Other', 'normalized_text': 'GDPR'}, {'start': 195, 'end': 202, 'probability': 0.5671, 'type': 'Other', 'normalized_text': 'LinkedIn'}], 'mentions': [{'start': 177, 'end': 191, 'username': 'linasbeliunas', 'id': '1294016945411563523'}]}  \n",
       "97                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           {'urls': [{'start': 45, 'end': 68, 'url': 'https://t.co/008B9TWrt3', 'expanded_url': 'https://twitter.com/pyra_m1d/status/1641843133393534984/photo/1', 'display_url': 'pic.twitter.com/008B9TWrt3', 'media_key': '16_1641843122291478530'}], 'annotations': [{'start': 0, 'end': 6, 'probability': 0.7101, 'type': 'Other', 'normalized_text': 'ChatGPT'}, {'start': 38, 'end': 42, 'probability': 0.9446, 'type': 'Place', 'normalized_text': 'Italy'}]}  \n",
       "98                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            {'urls': [{'start': 159, 'end': 182, 'url': 'https://t.co/0u0EwGMZjz', 'expanded_url': 'https://www.newscientist.com/article/2366824-reliably-detecting-ai-generated-text-is-mathematically-impossible/', 'display_url': 'newscientist.com/article/236682…', 'images': [{'url': 'https://pbs.twimg.com/news_img/1646847931176067072/-tGq--PC?format=jpg&name=orig', 'width': 1350, 'height': 900}, {'url': 'https://pbs.twimg.com/news_img/1646847931176067072/-tGq--PC?format=jpg&name=150x150', 'width': 150, 'height': 150}], 'status': 200, 'title': 'Reliably detecting AI-generated text is mathematically impossible | New Scientist', 'description': 'The ease with which artificial intelligence can generate and paraphrase language means that detectors to spot AI content will only be as accurate as flipping a coin', 'unwound_url': 'https://www.newscientist.com/article/2366824-reliably-detecting-ai-generated-text-is-mathematically-impossible/'}], 'annotations': [{'start': 75, 'end': 81, 'probability': 0.9415, 'type': 'Other', 'normalized_text': 'ChatGPT'}]}  \n",
       "99                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  nan  \n",
       "\n",
       "[10028 rows x 14 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d7ba69c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file\n",
    "fname_db = \"data/data1\"  #database filenmae\n",
    "df = DB.fetch(table_name='chatGPT_only', path=fname_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c62635",
   "metadata": {},
   "source": [
    "# Fetch tweets of specific users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "29559920",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_db = \"data/data1\"\n",
    "screen_name = 'OpenAI'\n",
    "max_results = 1000\n",
    "start_date = '2019-01-01'   \n",
    "end_date = '2023-04-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "31c3272e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-19 22:12:25.721] [INFO] [api:fetch_user_tweets:367] Fetched 100 tweets\n",
      "[2023-04-19 22:12:26.330] [INFO] [api:fetch_user_tweets:367] Fetched 100 tweets\n",
      "[2023-04-19 22:12:26.708] [INFO] [api:fetch_user_tweets:367] Fetched 22 tweets\n",
      "[2023-04-19 22:12:26.724] [INFO] [api:write:61] Writing 222 rows to table openAI\n"
     ]
    }
   ],
   "source": [
    "user_id =  User.user_info([screen_name]).id.values[0]\n",
    "df_ut = Tweet.fetch_user_tweets(user_id, start_date, end_date,max_results)\n",
    "    \n",
    "#add in a screen_name column for convenience\n",
    "df_ut['screen_name']= screen_name\n",
    "    \n",
    "#write dataframe to table\n",
    "DB.write(table_name='openAI', path=fname_db, data=df_ut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b51ad56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>geo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-24T16:06:47.000Z</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>We believe the number of users whose data was actually revealed to someone else is extremely low and we have contacted those who might be impacted. We take this very seriously and are sharing details of our investigation and plan here. 2/2 https://t.co/JwjfbcHr3g</td>\n",
       "      <td>en</td>\n",
       "      <td>300</td>\n",
       "      <td>217</td>\n",
       "      <td>2371</td>\n",
       "      <td>55</td>\n",
       "      <td>1639297716869275649</td>\n",
       "      <td>4398626122</td>\n",
       "      <td>1639297361729191936</td>\n",
       "      <td>4398626122</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-24T16:05:22.000Z</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>We took ChatGPT offline Monday to fix a bug in an open source library that allowed some users to see titles from other users’ chat history. Our investigation has also found that 1.2% of ChatGPT Plus users might have had personal data revealed to another user. 1/2</td>\n",
       "      <td>en</td>\n",
       "      <td>1235</td>\n",
       "      <td>830</td>\n",
       "      <td>8275</td>\n",
       "      <td>485</td>\n",
       "      <td>1639297361729191936</td>\n",
       "      <td>4398626122</td>\n",
       "      <td>1639297361729191936</td>\n",
       "      <td>nan</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-23T17:16:30.000Z</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>We are adding support for plugins to ChatGPT — extensions which integrate it with third-party services or allow it to access up-to-date information. We’re starting small to study real-world use, impact, and safety and alignment challenges: https://t.co/A9epaBBBzx https://t.co/KS5jcFoNhf</td>\n",
       "      <td>en</td>\n",
       "      <td>3995</td>\n",
       "      <td>795</td>\n",
       "      <td>19856</td>\n",
       "      <td>1459</td>\n",
       "      <td>1638952876281335813</td>\n",
       "      <td>4398626122</td>\n",
       "      <td>1638952876281335813</td>\n",
       "      <td>nan</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-17T04:00:08.000Z</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>Great news! ChatGPT Plus subscriptions are now available in India. Get early access to new features, including GPT-4 today: https://t.co/N6AiifcSXE</td>\n",
       "      <td>en</td>\n",
       "      <td>845</td>\n",
       "      <td>854</td>\n",
       "      <td>7275</td>\n",
       "      <td>188</td>\n",
       "      <td>1636578137298599936</td>\n",
       "      <td>4398626122</td>\n",
       "      <td>1636578137298599936</td>\n",
       "      <td>nan</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-14T17:05:19.000Z</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>Join us at 1 pm PT today for a developer demo livestream showing GPT-4 and its capabilities/limitations: https://t.co/xAg35cWkA5\\n\\n(comments in Discord: https://t.co/rH899bWeeD)</td>\n",
       "      <td>en</td>\n",
       "      <td>648</td>\n",
       "      <td>177</td>\n",
       "      <td>3295</td>\n",
       "      <td>131</td>\n",
       "      <td>1635688570710298625</td>\n",
       "      <td>4398626122</td>\n",
       "      <td>1635687373060317185</td>\n",
       "      <td>4398626122</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019-03-04T16:58:08.000Z</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>We’re releasing a Neural MMO — a massively multiagent game environment that supports numerous populations of agents: https://t.co/nED4DfUeEo\\n- Code: https://t.co/npVlxI0sTa\\n- 3D Client: https://t.co/k7t0gPXo2I https://t.co/tEVPjxE7yP</td>\n",
       "      <td>en</td>\n",
       "      <td>776</td>\n",
       "      <td>47</td>\n",
       "      <td>2303</td>\n",
       "      <td>93</td>\n",
       "      <td>1102614211237097472</td>\n",
       "      <td>4398626122</td>\n",
       "      <td>1102614211237097472</td>\n",
       "      <td>nan</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019-02-26T16:37:24.000Z</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>What we learned hosting our first Spinning Up in Deep RL workshop: https://t.co/qG4FMkoJgw\\nPlus:\\n- Video lectures: https://t.co/jzz3GdaJvi\\n- Spinning Up GitHub repo: https://t.co/uKddb2Gnzq https://t.co/m2ov0nxyYg</td>\n",
       "      <td>en</td>\n",
       "      <td>233</td>\n",
       "      <td>6</td>\n",
       "      <td>560</td>\n",
       "      <td>11</td>\n",
       "      <td>1100434666669039616</td>\n",
       "      <td>4398626122</td>\n",
       "      <td>1100434666669039616</td>\n",
       "      <td>nan</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019-02-19T16:21:24.000Z</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>AI safety needs social scientists (and we're hiring!): https://t.co/WQajMyVTOZ https://t.co/agAFS3be2U</td>\n",
       "      <td>en</td>\n",
       "      <td>298</td>\n",
       "      <td>24</td>\n",
       "      <td>716</td>\n",
       "      <td>39</td>\n",
       "      <td>1097893926902554629</td>\n",
       "      <td>4398626122</td>\n",
       "      <td>1097893926902554629</td>\n",
       "      <td>nan</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2019-02-14T17:03:59.000Z</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>We've trained an unsupervised language model that can generate coherent paragraphs and perform rudimentary reading comprehension, machine translation, question answering, and summarization — all without task-specific training: https://t.co/sY30aQM7hU https://t.co/360bGgoea3</td>\n",
       "      <td>en</td>\n",
       "      <td>2659</td>\n",
       "      <td>176</td>\n",
       "      <td>6279</td>\n",
       "      <td>763</td>\n",
       "      <td>1096092704709070851</td>\n",
       "      <td>4398626122</td>\n",
       "      <td>1096092704709070851</td>\n",
       "      <td>nan</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2019-02-02T16:31:46.000Z</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>Join our Spinning Up in Deep RL Workshop starting at 9amPT via livestream: https://t.co/jzz3GdaJvi</td>\n",
       "      <td>en</td>\n",
       "      <td>213</td>\n",
       "      <td>10</td>\n",
       "      <td>610</td>\n",
       "      <td>18</td>\n",
       "      <td>1091735942644170752</td>\n",
       "      <td>4398626122</td>\n",
       "      <td>1091735942644170752</td>\n",
       "      <td>nan</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>222 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  created_at screen_name  \\\n",
       "0   2023-03-24T16:06:47.000Z      OpenAI   \n",
       "1   2023-03-24T16:05:22.000Z      OpenAI   \n",
       "2   2023-03-23T17:16:30.000Z      OpenAI   \n",
       "3   2023-03-17T04:00:08.000Z      OpenAI   \n",
       "4   2023-03-14T17:05:19.000Z      OpenAI   \n",
       "..                       ...         ...   \n",
       "17  2019-03-04T16:58:08.000Z      OpenAI   \n",
       "18  2019-02-26T16:37:24.000Z      OpenAI   \n",
       "19  2019-02-19T16:21:24.000Z      OpenAI   \n",
       "20  2019-02-14T17:03:59.000Z      OpenAI   \n",
       "21  2019-02-02T16:31:46.000Z      OpenAI   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                               text  \\\n",
       "0                           We believe the number of users whose data was actually revealed to someone else is extremely low and we have contacted those who might be impacted. We take this very seriously and are sharing details of our investigation and plan here. 2/2 https://t.co/JwjfbcHr3g   \n",
       "1                           We took ChatGPT offline Monday to fix a bug in an open source library that allowed some users to see titles from other users’ chat history. Our investigation has also found that 1.2% of ChatGPT Plus users might have had personal data revealed to another user. 1/2   \n",
       "2   We are adding support for plugins to ChatGPT — extensions which integrate it with third-party services or allow it to access up-to-date information. We’re starting small to study real-world use, impact, and safety and alignment challenges: https://t.co/A9epaBBBzx https://t.co/KS5jcFoNhf   \n",
       "3                                                                                                                                               Great news! ChatGPT Plus subscriptions are now available in India. Get early access to new features, including GPT-4 today: https://t.co/N6AiifcSXE   \n",
       "4                                                                                                                Join us at 1 pm PT today for a developer demo livestream showing GPT-4 and its capabilities/limitations: https://t.co/xAg35cWkA5\\n\\n(comments in Discord: https://t.co/rH899bWeeD)   \n",
       "..                                                                                                                                                                                                                                                                                              ...   \n",
       "17                                                      We’re releasing a Neural MMO — a massively multiagent game environment that supports numerous populations of agents: https://t.co/nED4DfUeEo\\n- Code: https://t.co/npVlxI0sTa\\n- 3D Client: https://t.co/k7t0gPXo2I https://t.co/tEVPjxE7yP   \n",
       "18                                                                         What we learned hosting our first Spinning Up in Deep RL workshop: https://t.co/qG4FMkoJgw\\nPlus:\\n- Video lectures: https://t.co/jzz3GdaJvi\\n- Spinning Up GitHub repo: https://t.co/uKddb2Gnzq https://t.co/m2ov0nxyYg   \n",
       "19                                                                                                                                                                                           AI safety needs social scientists (and we're hiring!): https://t.co/WQajMyVTOZ https://t.co/agAFS3be2U   \n",
       "20               We've trained an unsupervised language model that can generate coherent paragraphs and perform rudimentary reading comprehension, machine translation, question answering, and summarization — all without task-specific training: https://t.co/sY30aQM7hU https://t.co/360bGgoea3   \n",
       "21                                                                                                                                                                                               Join our Spinning Up in Deep RL Workshop starting at 9amPT via livestream: https://t.co/jzz3GdaJvi   \n",
       "\n",
       "   lang  retweet_count  reply_count  like_count  quote_count  \\\n",
       "0    en            300          217        2371           55   \n",
       "1    en           1235          830        8275          485   \n",
       "2    en           3995          795       19856         1459   \n",
       "3    en            845          854        7275          188   \n",
       "4    en            648          177        3295          131   \n",
       "..  ...            ...          ...         ...          ...   \n",
       "17   en            776           47        2303           93   \n",
       "18   en            233            6         560           11   \n",
       "19   en            298           24         716           39   \n",
       "20   en           2659          176        6279          763   \n",
       "21   en            213           10         610           18   \n",
       "\n",
       "                     id   author_id      conversation_id in_reply_to_user_id  \\\n",
       "0   1639297716869275649  4398626122  1639297361729191936          4398626122   \n",
       "1   1639297361729191936  4398626122  1639297361729191936                 nan   \n",
       "2   1638952876281335813  4398626122  1638952876281335813                 nan   \n",
       "3   1636578137298599936  4398626122  1636578137298599936                 nan   \n",
       "4   1635688570710298625  4398626122  1635687373060317185          4398626122   \n",
       "..                  ...         ...                  ...                 ...   \n",
       "17  1102614211237097472  4398626122  1102614211237097472                 nan   \n",
       "18  1100434666669039616  4398626122  1100434666669039616                 nan   \n",
       "19  1097893926902554629  4398626122  1097893926902554629                 nan   \n",
       "20  1096092704709070851  4398626122  1096092704709070851                 nan   \n",
       "21  1091735942644170752  4398626122  1091735942644170752                 nan   \n",
       "\n",
       "     geo  \n",
       "0   None  \n",
       "1   None  \n",
       "2   None  \n",
       "3   None  \n",
       "4   None  \n",
       "..   ...  \n",
       "17  None  \n",
       "18  None  \n",
       "19  None  \n",
       "20  None  \n",
       "21  None  \n",
       "\n",
       "[222 rows x 13 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6214fa",
   "metadata": {},
   "source": [
    "# Fetch follwers of specific users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d4209f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_db = \"data/data1\"\n",
    "screen_names = ['OpenAI']\n",
    "max_following = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b0cc7978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-04-19 22:22:07.654] [INFO] [api:_fetch:95] Status code 429: sleeping for 15 minutes\n",
      "[2023-04-19 22:37:10.027] [INFO] [api:_fetch:95] Status code 429: sleeping for 15 minutes\n",
      "[2023-04-19 22:52:12.785] [INFO] [api:_fetch:95] Status code 429: sleeping for 15 minutes\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-ecc6f9bb3253>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_following\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFollow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscreen_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_following\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'followers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mDB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'OpenAI_following'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfname_db\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_following\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/MGT_575/project/scripts/api.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(cls, users, user_ids, kind, target_total, token_number)\u001b[0m\n",
      "\u001b[0;32m~/Desktop/MGT_575/project/scripts/api.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n",
      "\u001b[0;32m~/Desktop/MGT_575/project/scripts/api.py\u001b[0m in \u001b[0;36m_fetch\u001b[0;34m(cls, user_id, kind, target_total, token_number)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_following = Follow.fetch(users=screen_names, target_total = max_following, token_number = 0, kind='followers')\n",
    "DB.write(table_name='OpenAI_following', path=fname_db, data=df_following)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b30b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6458127c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
